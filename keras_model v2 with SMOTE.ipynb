{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import optuna\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to read OMG data from a CSV file\n",
    "def read_omg_csv(path_palm_data: str, \n",
    "                 n_omg_channels: int, \n",
    "                 n_acc_channels: int = 0, \n",
    "                 n_gyr_channels: int = 0, \n",
    "                 n_mag_channels: int = 0, \n",
    "                 n_enc_channels: int = 0,\n",
    "                 button_ch: bool = True, \n",
    "                 sync_ch: bool = True, \n",
    "                 timestamp_ch: bool = True) -> pd.DataFrame:\n",
    "    \n",
    "    df_raw = pd.read_csv(path_palm_data, sep=' ', \n",
    "                         header=None, \n",
    "                         skipfooter=1, \n",
    "                         skiprows=1, \n",
    "                         engine='python')\n",
    "    columns = np.arange(n_omg_channels).astype('str').tolist()\n",
    "    \n",
    "    for label, label_count in zip(['ACC', 'GYR', 'MAG', 'ENC'], \n",
    "                                  [n_acc_channels, n_gyr_channels, n_mag_channels, n_enc_channels]):\n",
    "        columns = columns + ['{}{}'.format(label, i) for i in range(label_count)]\n",
    "        \n",
    "    if button_ch:\n",
    "        columns = columns + ['BUTTON']\n",
    "        \n",
    "    if sync_ch:\n",
    "        columns = columns + ['SYNC']\n",
    "        \n",
    "    if timestamp_ch:\n",
    "        columns = columns + ['ts']\n",
    "        \n",
    "    df_raw.columns = columns\n",
    "    \n",
    "    return df_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_training_data(path_palm_data, path_protocol_data, path_meta_data, \n",
    "                          n_omg_channels=50, n_acc_channels=3, n_gyr_channels=3, \n",
    "                          n_mag_channels=0, n_enc_channels=6, \n",
    "                          standardize=True, normalize=True,\n",
    "                          DO_REPLACE_TO_MOVING_AVERAGE=True, \n",
    "                          DO_CALCULATE_DERIVATIVE=True,\n",
    "                          DO_SHIFT_GESTURE=True,\n",
    "                          selected_channels='ALL'):\n",
    "    \"\"\"\n",
    "    Подготовка данных для обучения и тестирования из файлов данных palm, protocol и meta.\n",
    "    \n",
    "    Аргументы:\n",
    "    path_palm_data (str): Путь к файлу данных palm.\n",
    "    path_protocol_data (str): Путь к файлу данных protocol.\n",
    "    path_meta_data (str): Путь к файлу данных meta.\n",
    "    n_omg_channels, n_acc_channels, и т.д. (int): Количество каналов сенсоров.\n",
    "    standardize (bool): Если True, стандартизирует признаки.\n",
    "    normalize (bool): Если True, нормализует признаки.\n",
    "    DO_REPLACE_TO_MOVING_AVERAGE (bool): Если True, применяет скользящее среднее к данным OMG.\n",
    "    DO_CALCULATE_DERIVATIVE (bool): Если True, вычисляет производные данных OMG.\n",
    "    DO_SHIFT_GESTURE (bool): Если True, смещает целевой признак на максимальный скачок в данных.\n",
    "    selected_channels (str): Выбор каналов данных ('OMG', 'ACC_GYR', 'ALL').\n",
    "    \n",
    "    Возвращает:\n",
    "    tuple: Кортеж, содержащий данные для обучения и тестирования.\n",
    "    \"\"\"\n",
    "    # Чтение данных OMG\n",
    "    omg_data = read_omg_csv(path_palm_data, n_omg_channels, n_acc_channels, n_gyr_channels, \n",
    "                            n_mag_channels, n_enc_channels)\n",
    "    \n",
    "    # Чтение данных протокола и кодирование жестов\n",
    "    gestures_protocol = pd.read_csv(path_protocol_data)\n",
    "    le = LabelEncoder()\n",
    "    gestures_protocol['gesture'] = le.fit_transform(\n",
    "        gestures_protocol[[\n",
    "            \"Thumb\", \"Index\", \"Middle\", \"Ring\", \"Pinky\",\n",
    "            'Thumb_stretch', 'Index_stretch', 'Middle_stretch', 'Ring_stretch', 'Pinky_stretch'\n",
    "        ]].apply(lambda row: str(tuple(row)), axis=1)\n",
    "    )\n",
    "    \n",
    "    # Чтение метаинформации\n",
    "    df_meta = pd.read_csv(path_meta_data)\n",
    "    palm_file = path_palm_data.split('/')[-1]\n",
    "    last_train_idx = df_meta[df_meta['montage'] == palm_file].to_dict(orient='records')[0]['last_train_idx']\n",
    "    \n",
    "    # Синхронизация меток жестов с данными OMG, используя канал SYNC\n",
    "    y_cmd = np.array([gestures_protocol['gesture'].loc[s] for s in omg_data['SYNC'].values])\n",
    "    \n",
    "    # Подготовка названий признаков для данных OMG\n",
    "    OMG_CH = [str(i) for i in range(n_omg_channels)]\n",
    "    ACC_CH = ['ACC0', 'ACC1', 'ACC2']\n",
    "    GYR_CH = ['GYR0', 'GYR1', 'GYR2']\n",
    "    ALL_CH = OMG_CH + ACC_CH + GYR_CH\n",
    "\n",
    "    # Выбор каналов в соответствии с параметром selected_channels\n",
    "    if selected_channels == 'OMG':\n",
    "        selected_features = OMG_CH\n",
    "    elif selected_channels == 'ACC_GYR':\n",
    "        selected_features = ACC_CH + GYR_CH\n",
    "    else:\n",
    "        selected_features = ALL_CH\n",
    "    \n",
    "    if DO_REPLACE_TO_MOVING_AVERAGE:\n",
    "        # Замена на скользящее среднее\n",
    "        for col in selected_features:\n",
    "            omg_data[col] = omg_data[col].rolling(window=5).mean().bfill()\n",
    "    \n",
    "    if DO_CALCULATE_DERIVATIVE:\n",
    "        # Вычисление производных данных\n",
    "        OMG_DERIV = [f'{col}_deriv' for col in OMG_CH]\n",
    "        for col in OMG_CH:\n",
    "            omg_data[f'{col}_next'] = omg_data[col].shift(-1).ffill()\n",
    "            omg_data[f'{col}_deriv'] = omg_data[f'{col}_next'] - omg_data[col]\n",
    "        selected_features += OMG_DERIV\n",
    "\n",
    "    if DO_SHIFT_GESTURE:\n",
    "        # Смещение целевого признака\n",
    "        id_max = 0\n",
    "        cur_gesture = 0\n",
    "        for i in range(y_cmd.shape[0]):\n",
    "            if i < id_max:  # Пропускаем все значения до id_max\n",
    "                continue\n",
    "            prev_gesture = cur_gesture  # предыдущий жест\n",
    "            cur_gesture = y_cmd[i]  # текущий жест\n",
    "            if cur_gesture != prev_gesture:  # Если сменился жест\n",
    "                id_max = omg_data[OMG_DERIV][i:i+35].abs().sum(axis=1).idxmax()  # Нахождение максимального скачка\n",
    "                y_cmd[i:id_max] = prev_gesture  # Замена всех значений до id_max на предыдущий жест\n",
    "    \n",
    "    # Разделение данных на обучающие и тестовые наборы\n",
    "    X_train = omg_data[selected_features].iloc[:last_train_idx].values\n",
    "    y_train = y_cmd[:last_train_idx]\n",
    "    X_test = omg_data[selected_features].iloc[last_train_idx:].values\n",
    "    y_test = y_cmd[last_train_idx:]\n",
    "    \n",
    "    # Стандартизация и нормализация\n",
    "    if standardize:\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        \n",
    "    if normalize:\n",
    "        scaler = MinMaxScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "    \n",
    "    return (X_train, y_train), (X_test, y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Running experiment1 ---\n",
      "Shapes of data: (15679, 106), (15679,), (3889, 106), (3889,)\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 850us/step\n",
      "--- Running experiment2 ---\n",
      "Shapes of data: (20756, 106), (20756,), (5892, 106), (5892,)\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 701us/step\n",
      "--- Running experiment3 ---\n",
      "Shapes of data: (5674, 106), (5674,), (5494, 106), (5494,)\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 666us/step\n",
      "--- Running experiment4 ---\n",
      "Shapes of data: (5677, 106), (5677,), (5497, 106), (5497,)\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 756us/step\n",
      "--- Running experiment5 ---\n",
      "Shapes of data: (5690, 106), (5690,), (5505, 106), (5505,)\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 704us/step\n",
      "--- Classification Report for experiment1 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96      2608\n",
      "           1       0.96      0.98      0.97       246\n",
      "           2       0.91      0.99      0.95       279\n",
      "           3       0.91      0.79      0.85       252\n",
      "           4       0.76      0.98      0.86       246\n",
      "           5       0.95      0.94      0.95       258\n",
      "\n",
      "    accuracy                           0.95      3889\n",
      "   macro avg       0.91      0.94      0.92      3889\n",
      "weighted avg       0.95      0.95      0.95      3889\n",
      "\n",
      "--- Classification Report for experiment2 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99      3715\n",
      "           1       0.98      0.98      0.98       494\n",
      "           2       0.98      1.00      0.99       438\n",
      "           3       0.96      0.97      0.97       439\n",
      "           4       0.91      1.00      0.95       431\n",
      "           5       0.98      0.95      0.97       375\n",
      "\n",
      "    accuracy                           0.98      5892\n",
      "   macro avg       0.97      0.98      0.97      5892\n",
      "weighted avg       0.98      0.98      0.98      5892\n",
      "\n",
      "--- Classification Report for experiment3 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.91      0.93      3759\n",
      "           1       0.72      0.81      0.76       274\n",
      "           2       0.89      0.86      0.88       377\n",
      "           3       0.85      0.73      0.79       410\n",
      "           4       0.53      0.83      0.64       375\n",
      "           5       0.94      0.80      0.87       299\n",
      "\n",
      "    accuracy                           0.88      5494\n",
      "   macro avg       0.81      0.82      0.81      5494\n",
      "weighted avg       0.89      0.88      0.88      5494\n",
      "\n",
      "--- Classification Report for experiment4 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.98      0.93      3781\n",
      "           1       0.96      0.92      0.94       340\n",
      "           2       0.81      0.85      0.83       347\n",
      "           3       0.97      0.47      0.63       380\n",
      "           4       0.47      0.37      0.41       357\n",
      "           5       0.98      0.59      0.74       292\n",
      "\n",
      "    accuracy                           0.87      5497\n",
      "   macro avg       0.85      0.70      0.75      5497\n",
      "weighted avg       0.87      0.87      0.86      5497\n",
      "\n",
      "--- Classification Report for experiment5 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97      3431\n",
      "           1       0.84      0.98      0.90       358\n",
      "           2       0.94      1.00      0.97       444\n",
      "           3       0.99      0.97      0.98       456\n",
      "           4       0.90      1.00      0.95       370\n",
      "           5       0.95      0.98      0.96       446\n",
      "\n",
      "    accuracy                           0.96      5505\n",
      "   macro avg       0.93      0.98      0.95      5505\n",
      "weighted avg       0.97      0.96      0.97      5505\n",
      "\n",
      "--- Best Parameters for experiment1 ---\n",
      "{'k_neighbors': 2, 'sampling_strategy': 'all', 'learning_rate': 0.00010322646860398609, 'dropout_rate': 0.2609382632562011, 'batch_size': 32}\n",
      "--- Best Parameters for experiment2 ---\n",
      "{'k_neighbors': 2, 'sampling_strategy': 'all', 'learning_rate': 0.00010322646860398609, 'dropout_rate': 0.2609382632562011, 'batch_size': 32}\n",
      "--- Best Parameters for experiment3 ---\n",
      "{'k_neighbors': 2, 'sampling_strategy': 'all', 'learning_rate': 0.00010322646860398609, 'dropout_rate': 0.2609382632562011, 'batch_size': 32}\n",
      "--- Best Parameters for experiment4 ---\n",
      "{'k_neighbors': 2, 'sampling_strategy': 'all', 'learning_rate': 0.00010322646860398609, 'dropout_rate': 0.2609382632562011, 'batch_size': 32}\n",
      "--- Best Parameters for experiment5 ---\n",
      "{'k_neighbors': 2, 'sampling_strategy': 'all', 'learning_rate': 0.00010322646860398609, 'dropout_rate': 0.2609382632562011, 'batch_size': 32}\n"
     ]
    }
   ],
   "source": [
    "base_path = 'data'\n",
    "\n",
    "# Словарь с данными по экспериментам, содержащий даты и типы файлов\n",
    "experiment_data = {\n",
    "    'experiment1': ('2023-05-31_17-14-41', 'palm'),\n",
    "    'experiment2': ('2023-05-05_17-57-30', 'palm'),\n",
    "    'experiment3': ('2023-10-25_08-52-30', 'palm'),\n",
    "    'experiment4': ('2023-10-18_11-16-21', 'palm'),\n",
    "    'experiment5': ('2023-09-29_09-20-47', 'palm')\n",
    "}\n",
    "\n",
    "def build_and_train_model(X_train, y_train, X_test, y_test, trial):\n",
    "    # Настройка параметров SMOTE в Optuna\n",
    "    k_neighbors = trial.suggest_int('k_neighbors', 2, 10)\n",
    "    sampling_strategy = trial.suggest_categorical('sampling_strategy', ['auto', 'minority', 'not majority', 'all'])\n",
    "    smote = SMOTE(k_neighbors=k_neighbors, sampling_strategy=sampling_strategy, n_jobs=-1)\n",
    "    X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "    # Настройка параметров модели с помощью Optuna\n",
    "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
    "    dropout_rate = trial.suggest_uniform('dropout_rate', 0.0, 0.7)\n",
    "    batch_size = trial.suggest_categorical('batch_size', [32, 64, 128, 256])\n",
    "    epochs = 100\n",
    "    num_classes = len(np.unique(y_resampled))\n",
    "\n",
    "    # Создание модели с динамически настроенными параметрами\n",
    "    model = Sequential([\n",
    "        Dense(128, activation='relu', input_shape=(X_resampled.shape[1],)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(128, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(X_resampled, y_resampled, epochs=epochs, batch_size=batch_size, validation_split=0.2, verbose=0)\n",
    "    test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "    return test_accuracy\n",
    "\n",
    "def build_final_model(X_train, y_train, best_params):\n",
    "    # Применение SMOTE с лучшими параметрами, найденными Optuna\n",
    "    smote = SMOTE(k_neighbors=best_params['k_neighbors'], sampling_strategy=best_params['sampling_strategy'], n_jobs=-1)\n",
    "    X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "    # Построение финальной модели с использованием лучших параметров\n",
    "    model = Sequential([\n",
    "        Dense(128, activation='relu', input_shape=(X_resampled.shape[1],)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(best_params['dropout_rate']),\n",
    "        Dense(128, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(best_params['dropout_rate']),\n",
    "        Dense(len(np.unique(y_resampled)), activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=best_params['learning_rate']),\n",
    "                  loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(X_resampled, y_resampled, epochs=100, batch_size=best_params['batch_size'], validation_split=0.2, verbose=0)\n",
    "    return model\n",
    "\n",
    "def run_experiments(use_optuna=True):\n",
    "    classification_reports = {}\n",
    "    best_parameters = {}\n",
    "    for experiment_name, (date_folder, file_suffix) in experiment_data.items():\n",
    "        # Формирование путей доступа к данным для каждого эксперимента\n",
    "        path_palm_data = f'{base_path}/{date_folder}.{file_suffix}'\n",
    "        path_protocol_data = f'{base_path}/{date_folder}.{file_suffix}.protocol.csv'\n",
    "        path_meta_data = f'{base_path}/meta_information.csv'\n",
    "\n",
    "        # Загрузка и подготовка данных\n",
    "        (X_train, y_train), (X_test, y_test) = prepare_training_data(path_palm_data, path_protocol_data, path_meta_data)\n",
    "        print(f'--- Running {experiment_name} ---')\n",
    "        print(f'Shapes of data: {X_train.shape}, {y_train.shape}, {X_test.shape}, {y_test.shape}')\n",
    "\n",
    "        # Оптимизация параметров с помощью Optuna или использование предустановленных параметров\n",
    "        if use_optuna:\n",
    "            study = optuna.create_study(direction='maximize')\n",
    "            objective = lambda trial: build_and_train_model(X_train, y_train, X_test, y_test, trial)\n",
    "            study.optimize(objective, n_trials=50, n_jobs=-1)\n",
    "            best_params = study.best_trial.params\n",
    "        else:\n",
    "            best_params = {\n",
    "                'k_neighbors': 2, \n",
    "                'sampling_strategy': 'all', \n",
    "                'learning_rate': 0.00010322646860398609, \n",
    "                'dropout_rate': 0.2609382632562011, \n",
    "                'batch_size': 32\n",
    "            }\n",
    "        best_parameters[experiment_name] = best_params\n",
    "\n",
    "        # Построение финальной модели и выполнение предсказаний\n",
    "        final_model = build_final_model(X_train, y_train, best_params)\n",
    "        y_pred = final_model.predict(X_test)\n",
    "        y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "        # Сохранение и вывод результатов классификации\n",
    "        classification_reports[experiment_name] = classification_report(y_test, y_pred_classes)\n",
    "\n",
    "    # Вывод всех отчетов о классификации и лучших параметров\n",
    "    for name, report in classification_reports.items():\n",
    "        print(f'--- Classification Report for {name} ---')\n",
    "        print(report)\n",
    "    for name, params in best_parameters.items():\n",
    "        print(f'--- Best Parameters for {name} ---')\n",
    "        print(params)\n",
    "\n",
    "run_experiments(use_optuna=False) # Установите `use_optuna=True`, чтобы использовать Optuna для оптимизации параметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if logistic_regression_optuna:\n",
    "#     def objective(trial):\n",
    "    \n",
    "#         # Параметры для SMOTE\n",
    "#         smote_k_neighbors = trial.suggest_int('smote_k_neighbors', 2, 15)\n",
    "#         smote_sampling_strategy = trial.suggest_categorical('smote_sampling_strategy', ['auto', 'minority', 'not majority', 'all'])\n",
    "\n",
    "#         # Параметры для логистической регрессии\n",
    "#         C = trial.suggest_loguniform('C', 1e-5, 10)\n",
    "#         max_iter = trial.suggest_int('max_iter', 1000, 10000)\n",
    "#         penalty = trial.suggest_categorical('penalty', ['l1', 'l2', 'elasticnet'])\n",
    "        \n",
    "#         # Установка совместимого решателя в зависимости от выбранной регуляризации\n",
    "#         if penalty == 'l1':\n",
    "#             solver = 'liblinear' # liblinear поддерживает только l1 и l2\n",
    "#         elif penalty == 'l2':\n",
    "#             solver = trial.suggest_categorical('solver', ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'])\n",
    "#         elif penalty == 'elasticnet':\n",
    "#             solver = 'saga'  # saga - единственный, который поддерживает elasticnet\n",
    "\n",
    "#         # Применение SMOTE\n",
    "#         smote = SMOTE(k_neighbors=smote_k_neighbors, sampling_strategy=smote_sampling_strategy)\n",
    "#         X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "#         # Обучение модели логистической регрессии\n",
    "#         model = LogisticRegression(C=C, max_iter=max_iter, penalty=penalty, solver=solver, l1_ratio=0.5 if penalty == 'elasticnet' else None)\n",
    "#         model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "#         # Оценка модели\n",
    "#         score = f1_score(\n",
    "#             y_test, \n",
    "#             model.predict(X_test), \n",
    "#             average = 'micro'\n",
    "#         )\n",
    "#         return score\n",
    "\n",
    "#     # Создание исследования\n",
    "#     study = optuna.create_study(direction='maximize')\n",
    "#     study.optimize(objective, n_trials=100, n_jobs=-1)\n",
    "\n",
    "#     print(\"Лучшие параметры:\", study.best_trial.params)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if logistic_regression_optuna:\n",
    "#     # Извлечение лучших параметров\n",
    "#     best_params = study.best_trial.params\n",
    "#     print(\"Лучшие параметры:\", best_params)\n",
    "\n",
    "#     # Применение SMOTE с лучшими параметрами\n",
    "#     smote = SMOTE(k_neighbors=best_params['smote_k_neighbors'], sampling_strategy=best_params['smote_sampling_strategy'])\n",
    "#     X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "#     # Выбор решателя в зависимости от типа регуляризации\n",
    "#     if best_params['penalty'] == 'elasticnet':\n",
    "#         solver = 'saga'  # saga - единственный решатель, поддерживающий elasticnet\n",
    "#     elif best_params['penalty'] == 'l1':\n",
    "#         solver = 'liblinear'  # liblinear - оптимальный выбор для l1 регуляризации\n",
    "#     elif best_params['penalty'] == 'l2':\n",
    "#         solver = best_params['solver'] \n",
    "#     else:  # 'none'\n",
    "#         solver = 'lbfgs'  # lbfgs хорошо подходит для отсутствия регуляризации\n",
    "\n",
    "#     # Построение и обучение модели логистической регрессии\n",
    "#     model = LogisticRegression(\n",
    "#         C=best_params['C'],\n",
    "#         max_iter=best_params['max_iter'],\n",
    "#         penalty=best_params['penalty'],\n",
    "#         solver=solver,\n",
    "#         l1_ratio=0.5 if best_params['penalty'] == 'elasticnet' else None,\n",
    "#         multi_class='auto',\n",
    "#         class_weight={0: 1, 1: 1, 2: 1, 3: 3, 4: 1, 5: 1}\n",
    "#     )\n",
    "\n",
    "#     model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "#     #Делаем предсказание класса\n",
    "#     y_pred = model.predict(X_test)\n",
    "\n",
    "#     print(f'Метрики на валидационной выборке \\n\\\n",
    "#     {classification_report(y_test, y_pred)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
