{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import optuna\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import glob\n",
    "import re\n",
    "import dataframe_image as dfi\n",
    "from pyod.models.hbos import HBOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_omg_csv(path_palm_data: str, \n",
    "                 n_omg_channels: int, \n",
    "                 n_acc_channels: int = 0, \n",
    "                 n_gyr_channels: int = 0, \n",
    "                 n_mag_channels: int = 0, \n",
    "                 n_enc_channels: int = 0,\n",
    "                 button_ch: bool = True, \n",
    "                 sync_ch: bool = True, \n",
    "                 timestamp_ch: bool = True) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Читает данные CSV для OMG данных с определенными параметрами каналов.\n",
    "\n",
    "    Parameters:\n",
    "    path_palm_data (str): Путь к файлу данных CSV.\n",
    "    n_omg_channels (int): Количество каналов OMG.\n",
    "    n_acc_channels (int): Количество каналов акселерометра. По умолчанию 0.\n",
    "    n_gyr_channels (int): Количество каналов гироскопа. По умолчанию 0.\n",
    "    n_mag_channels (int): Количество каналов магнетометра. По умолчанию 0.\n",
    "    n_enc_channels (int): Количество каналов энкодера. По умолчанию 0.\n",
    "    button_ch (bool): Наличие канала кнопки. По умолчанию True.\n",
    "    sync_ch (bool): Наличие канала синхронизации. По умолчанию True.\n",
    "    timestamp_ch (bool): Наличие временной метки. По умолчанию True.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame с прочитанными и отформатированными данными OMG.\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Чтение данных из файла CSV с помощью pandas\n",
    "        df_raw = pd.read_csv(path_palm_data, sep=' ', header=None, skipfooter=1, skiprows=1, engine='python')\n",
    "        \n",
    "        # Генерация списка названий столбцов\n",
    "        columns = [str(i) for i in range(n_omg_channels)]\n",
    "        labels = ['ACC', 'GYR', 'MAG', 'ENC']\n",
    "        channels = [n_acc_channels, n_gyr_channels, n_mag_channels, n_enc_channels]\n",
    "\n",
    "        for label, count in zip(labels, channels):\n",
    "            columns += [f'{label}{i}' for i in range(count)]\n",
    "\n",
    "        if button_ch:\n",
    "            columns.append('BUTTON')\n",
    "        \n",
    "        if sync_ch:\n",
    "            columns.append('SYNC')\n",
    "        \n",
    "        if timestamp_ch:\n",
    "            columns.append('ts')\n",
    "        \n",
    "        # Присвоение названий столбцов DataFrame\n",
    "        df_raw.columns = columns\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f'Ошибка при чтении файла: {e}')\n",
    "        return pd.DataFrame()  # Возврат пустого DataFrame в случае ошибки\n",
    "\n",
    "    return df_raw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_anomaly_with_interpolation(df: pd.DataFrame, OMG_CH: list, contamination: float = 0.05) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Очистка датасета от аномалий с использованием интерполяции для выбранных каналов.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): Исходный DataFrame, который необходимо очистить.\n",
    "    OMG_CH (list): Список каналов, для которых необходимо очистить аномалии.\n",
    "    contamination (float): Процент аномальных данных, который ожидается в данных.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame без аномальных значений в указанных каналах.\n",
    "    \"\"\"\n",
    "    df_clean = df.copy()\n",
    "    clf = HBOS(contamination=contamination)\n",
    "\n",
    "    for column in OMG_CH:\n",
    "        clf.fit(df_clean[[column]])  # Обучение на колонке\n",
    "        anomaly_scores = clf.predict(df_clean[[column]])  # Определение аномалий\n",
    "        \n",
    "        # Использование линейной интерполяции для заполнения аномалий\n",
    "        anomalies = anomaly_scores == 1\n",
    "        df_clean.loc[anomalies, column] = np.nan  # Пометка аномалий как NaN для интерполяции\n",
    "        df_clean[column] = df_clean[column].interpolate(method='linear', limit_direction='both')\n",
    "\n",
    "    return df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_training_data(path_palm_data, path_protocol_data, path_meta_data, \n",
    "                          n_omg_channels=50, n_acc_channels=3, n_gyr_channels=3, \n",
    "                          n_mag_channels=0, n_enc_channels=6, \n",
    "                          standardize=True, normalize=True,\n",
    "                          DO_REPLACE_TO_MOVING_AVERAGE=True, \n",
    "                          DO_CALCULATE_DERIVATIVE=True,\n",
    "                          DO_SHIFT_GESTURE=True,\n",
    "                          selected_channels='ALL'):\n",
    "    \"\"\"\n",
    "    Подготовка данных для обучения и тестирования из файлов данных palm, protocol и meta.\n",
    "    \"\"\"\n",
    "    # Чтение данных OMG\n",
    "    omg_data = read_omg_csv(path_palm_data, n_omg_channels, n_acc_channels, n_gyr_channels, \n",
    "                            n_mag_channels, n_enc_channels)\n",
    "    \n",
    "    # Определение списка каналов для очистки от аномалий\n",
    "    OMG_CH = [str(i) for i in range(n_omg_channels)]\n",
    "    omg_data[OMG_CH] = clear_anomaly_with_interpolation(omg_data[OMG_CH], OMG_CH, contamination=0.05)\n",
    "    \n",
    "    # Чтение данных протокола и кодирование жестов\n",
    "    gestures_protocol = pd.read_csv(path_protocol_data)\n",
    "    le = LabelEncoder()\n",
    "    gestures_protocol['gesture'] = le.fit_transform(\n",
    "        gestures_protocol[[\n",
    "            \"Thumb\", \"Index\", \"Middle\", \"Ring\", \"Pinky\",\n",
    "            'Thumb_stretch', 'Index_stretch', 'Middle_stretch', 'Ring_stretch', 'Pinky_stretch'\n",
    "        ]].apply(lambda row: str(tuple(row)), axis=1)\n",
    "    )\n",
    "    \n",
    "    # Чтение метаинформации\n",
    "    df_meta = pd.read_csv(path_meta_data)\n",
    "    palm_file = path_palm_data.split('/')[-1]\n",
    "    last_train_idx = df_meta[df_meta['montage'] == palm_file].to_dict(orient='records')[0]['last_train_idx']\n",
    "    \n",
    "    # Синхронизация меток жестов с данными OMG, используя канал SYNC\n",
    "    y_cmd = np.array([gestures_protocol['gesture'].loc[s] for s in omg_data['SYNC'].values])\n",
    "    \n",
    "    # Выбор каналов в соответствии с параметром selected_channels\n",
    "    selected_features = OMG_CH  # Изначально выбираем все каналы OMG\n",
    "    if selected_channels == 'ACC_GYR':\n",
    "        selected_features = ['ACC0', 'ACC1', 'ACC2', 'GYR0', 'GYR1', 'GYR2']\n",
    "    elif selected_channels == 'ALL':\n",
    "        selected_features = OMG_CH + ['ACC0', 'ACC1', 'ACC2', 'GYR0', 'GYR1', 'GYR2']\n",
    "    \n",
    "    if DO_REPLACE_TO_MOVING_AVERAGE:\n",
    "        # Замена на скользящее среднее\n",
    "        for col in selected_features:\n",
    "            omg_data[col] = omg_data[col].rolling(window=5).mean().bfill()\n",
    "    \n",
    "    if DO_CALCULATE_DERIVATIVE:\n",
    "        # Вычисление производных данных\n",
    "        OMG_DERIV = [f'{col}_deriv' for col in OMG_CH]\n",
    "        for col in OMG_CH:\n",
    "            omg_data[f'{col}_next'] = omg_data[col].shift(-1).ffill()\n",
    "            omg_data[f'{col}_deriv'] = omg_data[f'{col}_next'] - omg_data[col]\n",
    "        selected_features += OMG_DERIV\n",
    "\n",
    "    if DO_SHIFT_GESTURE:\n",
    "        # Смещение целевого признака\n",
    "        id_max = 0\n",
    "        cur_gesture = 0\n",
    "        for i in range(y_cmd.shape[0]):\n",
    "            if i < id_max:  # Пропускаем все значения до id_max\n",
    "                continue\n",
    "            prev_gesture = cur_gesture  # предыдущий жест\n",
    "            cur_gesture = y_cmd[i]  # текущий жест\n",
    "            if cur_gesture != prev_gesture:  # Если сменился жест\n",
    "                id_max = omg_data[OMG_DERIV][i:i+35].abs().sum(axis=1).idxmax()  # Нахождение максимального скачка\n",
    "                y_cmd[i:id_max] = prev_gesture  # Замена всех значений до id_max на предыдущий жест\n",
    "    \n",
    "    # Разделение данных на обучающие и тестовые наборы\n",
    "    X_train = omg_data[selected_features].iloc[:last_train_idx].values\n",
    "    y_train = y_cmd[:last_train_idx]\n",
    "    X_test = omg_data[selected_features].iloc[last_train_idx:].values\n",
    "    y_test = y_cmd[last_train_idx:]\n",
    "    \n",
    "    # Стандартизация и нормализация\n",
    "    if standardize:\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        \n",
    "    if normalize:\n",
    "        scaler = MinMaxScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "    \n",
    "    return (X_train, y_train), (X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def prepare_training_data(path_palm_data, path_protocol_data, path_meta_data, \n",
    "#                           n_omg_channels=50, n_acc_channels=3, n_gyr_channels=3, \n",
    "#                           n_mag_channels=0, n_enc_channels=6, \n",
    "#                           standardize=True, normalize=True,\n",
    "#                           DO_REPLACE_TO_MOVING_AVERAGE=True, \n",
    "#                           DO_CALCULATE_DERIVATIVE=True,\n",
    "#                           DO_SHIFT_GESTURE=True,\n",
    "#                           selected_channels='ALL'):\n",
    "#     \"\"\"\n",
    "#     Подготовка данных для обучения и тестирования из файлов данных palm, protocol и meta.\n",
    "    \n",
    "#     Аргументы:\n",
    "#     path_palm_data (str): Путь к файлу данных palm.\n",
    "#     path_protocol_data (str): Путь к файлу данных protocol.\n",
    "#     path_meta_data (str): Путь к файлу данных meta.\n",
    "#     n_omg_channels, n_acc_channels, и т.д. (int): Количество каналов сенсоров.\n",
    "#     standardize (bool): Если True, стандартизирует признаки.\n",
    "#     normalize (bool): Если True, нормализует признаки.\n",
    "#     DO_REPLACE_TO_MOVING_AVERAGE (bool): Если True, применяет скользящее среднее к данным OMG.\n",
    "#     DO_CALCULATE_DERIVATIVE (bool): Если True, вычисляет производные данных OMG.\n",
    "#     DO_SHIFT_GESTURE (bool): Если True, смещает целевой признак на максимальный скачок в данных.\n",
    "#     selected_channels (str): Выбор каналов данных ('OMG', 'ACC_GYR', 'ALL').\n",
    "    \n",
    "#     Возвращает:\n",
    "#     tuple: Кортеж, содержащий данные для обучения и тестирования.\n",
    "#     \"\"\"\n",
    "#     # Чтение данных OMG\n",
    "#     omg_data = read_omg_csv(path_palm_data, n_omg_channels, n_acc_channels, n_gyr_channels, \n",
    "#                             n_mag_channels, n_enc_channels)\n",
    "    \n",
    "#     # Чтение данных протокола и кодирование жестов\n",
    "#     gestures_protocol = pd.read_csv(path_protocol_data)\n",
    "#     le = LabelEncoder()\n",
    "#     gestures_protocol['gesture'] = le.fit_transform(\n",
    "#         gestures_protocol[[\n",
    "#             \"Thumb\", \"Index\", \"Middle\", \"Ring\", \"Pinky\",\n",
    "#             'Thumb_stretch', 'Index_stretch', 'Middle_stretch', 'Ring_stretch', 'Pinky_stretch'\n",
    "#         ]].apply(lambda row: str(tuple(row)), axis=1)\n",
    "#     )\n",
    "    \n",
    "#     # Чтение метаинформации\n",
    "#     df_meta = pd.read_csv(path_meta_data)\n",
    "#     palm_file = path_palm_data.split('/')[-1]\n",
    "#     last_train_idx = df_meta[df_meta['montage'] == palm_file].to_dict(orient='records')[0]['last_train_idx']\n",
    "    \n",
    "#     # Синхронизация меток жестов с данными OMG, используя канал SYNC\n",
    "#     y_cmd = np.array([gestures_protocol['gesture'].loc[s] for s in omg_data['SYNC'].values])\n",
    "    \n",
    "#     # Подготовка названий признаков для данных OMG\n",
    "#     OMG_CH = [str(i) for i in range(n_omg_channels)]\n",
    "#     ACC_CH = ['ACC0', 'ACC1', 'ACC2']\n",
    "#     GYR_CH = ['GYR0', 'GYR1', 'GYR2']\n",
    "#     ALL_CH = OMG_CH + ACC_CH + GYR_CH\n",
    "\n",
    "#     # Выбор каналов в соответствии с параметром selected_channels\n",
    "#     if selected_channels == 'OMG':\n",
    "#         selected_features = OMG_CH\n",
    "#     elif selected_channels == 'ACC_GYR':\n",
    "#         selected_features = ACC_CH + GYR_CH\n",
    "#     else:\n",
    "#         selected_features = ALL_CH\n",
    "    \n",
    "#     if DO_REPLACE_TO_MOVING_AVERAGE:\n",
    "#         # Замена на скользящее среднее\n",
    "#         for col in selected_features:\n",
    "#             omg_data[col] = omg_data[col].rolling(window=5).mean().bfill()\n",
    "    \n",
    "#     if DO_CALCULATE_DERIVATIVE:\n",
    "#         # Вычисление производных данных\n",
    "#         OMG_DERIV = [f'{col}_deriv' for col in OMG_CH]\n",
    "#         for col in OMG_CH:\n",
    "#             omg_data[f'{col}_next'] = omg_data[col].shift(-1).ffill()\n",
    "#             omg_data[f'{col}_deriv'] = omg_data[f'{col}_next'] - omg_data[col]\n",
    "#         selected_features += OMG_DERIV\n",
    "\n",
    "#     if DO_SHIFT_GESTURE:\n",
    "#         # Смещение целевого признака\n",
    "#         id_max = 0\n",
    "#         cur_gesture = 0\n",
    "#         for i in range(y_cmd.shape[0]):\n",
    "#             if i < id_max:  # Пропускаем все значения до id_max\n",
    "#                 continue\n",
    "#             prev_gesture = cur_gesture  # предыдущий жест\n",
    "#             cur_gesture = y_cmd[i]  # текущий жест\n",
    "#             if cur_gesture != prev_gesture:  # Если сменился жест\n",
    "#                 id_max = omg_data[OMG_DERIV][i:i+35].abs().sum(axis=1).idxmax()  # Нахождение максимального скачка\n",
    "#                 y_cmd[i:id_max] = prev_gesture  # Замена всех значений до id_max на предыдущий жест\n",
    "    \n",
    "#     # Разделение данных на обучающие и тестовые наборы\n",
    "#     X_train = omg_data[selected_features].iloc[:last_train_idx].values\n",
    "#     y_train = y_cmd[:last_train_idx]\n",
    "#     X_test = omg_data[selected_features].iloc[last_train_idx:].values\n",
    "#     y_test = y_cmd[last_train_idx:]\n",
    "    \n",
    "#     # Стандартизация и нормализация\n",
    "#     if standardize:\n",
    "#         scaler = StandardScaler()\n",
    "#         X_train = scaler.fit_transform(X_train)\n",
    "#         X_test = scaler.transform(X_test)\n",
    "        \n",
    "#     if normalize:\n",
    "#         scaler = MinMaxScaler()\n",
    "#         X_train = scaler.fit_transform(X_train)\n",
    "#         X_test = scaler.transform(X_test)\n",
    "    \n",
    "#     return (X_train, y_train), (X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее будем фильтровать датасеты на основе метрики F1. Параметры для нейросети и SMOTE были подобраны ниже в ноутбуке при обучении вот на этих данных:\n",
    "- '2023-05-31_17-14-41'\n",
    "- '2023-05-05_17-57-30'\n",
    "- '2023-10-25_08-52-30'\n",
    "- '2023-10-18_11-16-21'\n",
    "- '2023-09-29_09-20-47'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Processing 2023-05-05_17-57-30.palm---\n",
      "\u001b[1m649/649\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 721us/step - accuracy: 0.9630 - loss: 0.1737\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 593us/step\n",
      "---Processing 2023-05-07_15-19-05.palm---\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690us/step - accuracy: 0.9276 - loss: 0.4181\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 598us/step\n",
      "---Processing 2023-05-07_16-54-27.palm---\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 712us/step - accuracy: 0.9412 - loss: 0.3465\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 618us/step\n",
      "---Processing 2023-05-12_19-17-00.palm---\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 700us/step - accuracy: 0.8934 - loss: 0.3852\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 731us/step\n",
      "---Processing 2023-05-15_16-16-08.palm---\n",
      "\u001b[1m730/730\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 691us/step - accuracy: 0.8896 - loss: 0.3737\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 608us/step\n",
      "---Processing 2023-05-15_17-12-24.palm---\n",
      "\u001b[1m730/730\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 727us/step - accuracy: 0.8009 - loss: 0.5854\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 597us/step\n",
      "---Processing 2023-05-19_12-04-02.palm---\n",
      "\u001b[1m729/729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 696us/step - accuracy: 0.9593 - loss: 0.1919\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 589us/step\n",
      "---Processing 2023-05-22_17-04-29.palm---\n",
      "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 726us/step - accuracy: 0.9680 - loss: 0.1468\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 599us/step\n",
      "---Processing 2023-05-22_20-22-01.palm---\n",
      "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819us/step - accuracy: 0.9709 - loss: 0.1599\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 857us/step\n",
      "---Processing 2023-05-31_15-46-37.palm---\n",
      "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 828us/step - accuracy: 0.9241 - loss: 0.3566\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step\n",
      "---Processing 2023-05-31_17-14-41.palm---\n",
      "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step - accuracy: 0.9471 - loss: 0.3488\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 743us/step\n",
      "---Processing 2023-06-05_16-12-38.palm---\n",
      "\u001b[1m561/561\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step - accuracy: 0.8782 - loss: 0.4055\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 781us/step\n",
      "---Processing 2023-06-05_17-53-01.palm---\n",
      "\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 828us/step - accuracy: 0.8854 - loss: 0.3957\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 724us/step\n",
      "---Processing 2023-06-20_12-34-17.palm---\n",
      "\u001b[1m555/555\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 822us/step - accuracy: 0.8791 - loss: 0.3676\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 723us/step\n",
      "---Processing 2023-06-20_13-30-15.palm---\n",
      "\u001b[1m561/561\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step - accuracy: 0.8922 - loss: 0.3469\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 763us/step\n",
      "---Processing 2023-06-20_14-43-11.palm---\n",
      "\u001b[1m561/561\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 847us/step - accuracy: 0.8629 - loss: 0.4478\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 744us/step\n",
      "---Processing 2023-09-12_12-55-22.palm---\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 821us/step - accuracy: 0.9030 - loss: 0.7724\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 925us/step\n",
      "---Processing 2023-09-12_14-59-23.palm---\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - accuracy: 0.9419 - loss: 0.3394\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 847us/step\n",
      "---Processing 2023-09-13_22-14-05.palm---\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 796us/step - accuracy: 0.9543 - loss: 0.3152\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 936us/step\n",
      "---Processing 2023-09-29_09-20-47.palm---\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 866us/step - accuracy: 0.9337 - loss: 0.3755\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710us/step\n",
      "---Processing 2023-09-29_11-03-50.palm---\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 852us/step - accuracy: 0.9485 - loss: 0.2945\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 707us/step\n",
      "---Processing 2023-09-30_08-06-44.palm---\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 863us/step - accuracy: 0.9410 - loss: 0.3623\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 681us/step\n",
      "---Processing 2023-10-18_08-05-29.palm---\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 833us/step - accuracy: 0.9183 - loss: 0.4830\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 743us/step\n",
      "---Processing 2023-10-18_11-16-21.palm---\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 893us/step - accuracy: 0.9158 - loss: 0.4692\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 760us/step\n",
      "---Processing 2023-10-23_10-11-45.palm---\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 825us/step - accuracy: 0.9407 - loss: 0.2591\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 664us/step\n",
      "---Processing 2023-10-23_14-07-13.palm---\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9249 - loss: 0.4424\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "---Processing 2023-10-23_16-23-02.palm---\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 961us/step - accuracy: 0.9406 - loss: 0.3936\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 778us/step\n",
      "---Processing 2023-10-25_08-52-30.palm---\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 846us/step - accuracy: 0.8993 - loss: 0.5200\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 684us/step\n",
      "---Processing 2023-10-25_11-08-46.palm---\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 757us/step - accuracy: 0.7601 - loss: 0.9050\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 743us/step\n"
     ]
    }
   ],
   "source": [
    "# выбираем, нужно ли нам отбирать хорошие датасеты\n",
    "to_choose_good_datasets = True\n",
    "\n",
    "if to_choose_good_datasets:\n",
    "    # функция для построения модели \n",
    "    def build_model(X_train, y_train, best_params):\n",
    "        \"\"\" Построение модели с использованием лучших параметров, найденных ранее через Optuna. \"\"\"\n",
    "        smote = SMOTE(k_neighbors=best_params['k_neighbors'], sampling_strategy=best_params['sampling_strategy'], n_jobs=-1)\n",
    "        X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "        model = Sequential([\n",
    "            Dense(128, activation='relu', input_shape=(X_resampled.shape[1],)),\n",
    "            BatchNormalization(),\n",
    "            Dropout(best_params['dropout_rate']),\n",
    "            Dense(128, activation='relu'),\n",
    "            BatchNormalization(),\n",
    "            Dropout(best_params['dropout_rate']),\n",
    "            Dense(len(np.unique(y_resampled)), activation='softmax')\n",
    "        ])\n",
    "        model.compile(optimizer=Adam(learning_rate=best_params['learning_rate']),\n",
    "                    loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "        model.fit(X_resampled, y_resampled, epochs=100, batch_size=best_params['batch_size'], validation_split=0.2, verbose=0)\n",
    "        return model\n",
    "\n",
    "    # функция для рассчета метрики\n",
    "    def evaluate_dataset(model, X, y):\n",
    "        \"\"\" Оценка датасета с помощью модели для получения F1-скора. \"\"\"\n",
    "        predictions = model.predict(X)\n",
    "        predictions = np.argmax(predictions, axis=1)  # Получаем индексы максимальных значений для многоклассовой классификации\n",
    "        f1 = f1_score(y, predictions, average='weighted')\n",
    "        return f1\n",
    "\n",
    "    # функция фильтрации датасетов\n",
    "    def filter_datasets(base_path, quality_threshold, best_params):\n",
    "        \"\"\"\n",
    "        Фильтрация датасетов на основе F1-скора, полученного от нейросети, с использованием строгого формата имен файлов.\n",
    "        \n",
    "        Args:\n",
    "        base_path (str): Базовый путь к данным.\n",
    "        model (Model): Предварительно обученная модель для оценки датасетов.\n",
    "        quality_threshold (float): Порог F1-скора для включения датасета в обработку.\n",
    "        \n",
    "        Returns:\n",
    "        dict: Список путей к файлам данных .palm, которые прошли фильтрацию.\n",
    "        \"\"\"\n",
    "        # Компилируем паттерн для проверки имени файла\n",
    "        pattern = re.compile(r'\\d{4}-\\d{2}-\\d{2}_\\d{2}-\\d{2}-\\d{2}\\.palm$')\n",
    "        \n",
    "        # Собираем список всех файлов, соответствующих шаблону\n",
    "        all_files = [file for file in os.listdir(base_path) if pattern.match(file)]\n",
    "        good_datasets = {}\n",
    "\n",
    "        for file_name in all_files:\n",
    "            print(f'---Processing {file_name}---')\n",
    "            path_palm_data = f'{base_path}/{file_name}'\n",
    "            path_protocol_data = f'{base_path}/{file_name}.protocol.csv'\n",
    "            path_meta_data = f'{base_path}/meta_information.csv'\n",
    "            # Загрузка и подготовка данных\n",
    "            (X_train, y_train), (X_test, y_test) = prepare_training_data(path_palm_data, path_protocol_data, path_meta_data)\n",
    "            \n",
    "            #строим модель \n",
    "            model = build_model(X_train, y_train, best_params)\n",
    "            \n",
    "            # Обучение модели и оценка на валидационном наборе\n",
    "            model.fit(X_train, y_train)\n",
    "            f1 = evaluate_dataset(model, X_test, y_test)\n",
    "            \n",
    "            \n",
    "            #if f1 >= quality_threshold:\n",
    "            good_datasets[file_name] = f1\n",
    "\n",
    "        return good_datasets\n",
    "    #создаем список хороших датасетов и записываем в файл\n",
    "    base_path = 'data'\n",
    "    best_params = {'k_neighbors': 10,\n",
    "        'sampling_strategy': 'not majority',\n",
    "        'learning_rate': 0.010594467077472143,\n",
    "        'dropout_rate': 0.16185277449744218,\n",
    "        'batch_size': 128}\n",
    "    quality_threshold = 0.7\n",
    "    good_datasets = filter_datasets(base_path, quality_threshold, best_params)\n",
    "    good_datasets = pd.DataFrame(list(good_datasets.items()), columns=['FileName', 'F1-Score'])\n",
    "    good_datasets = good_datasets.sort_values(by='F1-Score')\n",
    "    dfi.export(good_datasets, 'good_datasets.png', chrome_path='C:\\Program Files\\Google\\Chrome\\Application\\chrome.exe')\n",
    "    good_datasets.to_csv('data/good_datasets_keras.csv', index=False)\n",
    "else:\n",
    "  good_datasets = pd.read_csv('data/good_datasets_keras.csv')['FileName'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Running file1 ---\n",
      "Shapes of data: (15679, 106), (15679,), (3889, 106), (3889,)\n",
      "--- Running file2 ---\n",
      "Shapes of data: (20756, 106), (20756,), (5892, 106), (5892,)\n",
      "--- Running file3 ---\n",
      "Shapes of data: (5674, 106), (5674,), (5494, 106), (5494,)\n",
      "--- Running file4 ---\n",
      "Shapes of data: (5677, 106), (5677,), (5497, 106), (5497,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-16 20:36:46,116] A new study created in memory with name: no-name-3c09267d-4e28-4185-a9c0-bb8523855c01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Running file5 ---\n",
      "Shapes of data: (5690, 106), (5690,), (5505, 106), (5505,)\n",
      "--- Final shapes ---\n",
      "Shapes of data: (53476, 106), (53476,), (26277, 106), (26277,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-16 20:45:08,389] Trial 22 finished with value: 0.8146287798881531 and parameters: {'k_neighbors': 7, 'sampling_strategy': 'minority', 'learning_rate': 0.0872025848204322, 'dropout_rate': 0.17622305196662846, 'batch_size': 256}. Best is trial 22 with value: 0.8146287798881531.\n",
      "[I 2024-05-16 20:45:09,121] Trial 24 finished with value: 0.8233816623687744 and parameters: {'k_neighbors': 9, 'sampling_strategy': 'minority', 'learning_rate': 1.766673634797885e-05, 'dropout_rate': 0.388913470139653, 'batch_size': 256}. Best is trial 24 with value: 0.8233816623687744.\n",
      "[I 2024-05-16 20:53:40,808] Trial 32 finished with value: 0.8462914228439331 and parameters: {'k_neighbors': 7, 'sampling_strategy': 'minority', 'learning_rate': 0.0009871077961390274, 'dropout_rate': 0.6395507689164328, 'batch_size': 256}. Best is trial 32 with value: 0.8462914228439331.\n",
      "[I 2024-05-16 20:56:43,008] Trial 14 finished with value: 0.8945465683937073 and parameters: {'k_neighbors': 5, 'sampling_strategy': 'all', 'learning_rate': 0.0006870209768592219, 'dropout_rate': 0.5421339158170111, 'batch_size': 256}. Best is trial 14 with value: 0.8945465683937073.\n",
      "[I 2024-05-16 20:56:49,548] Trial 6 finished with value: 0.8370818495750427 and parameters: {'k_neighbors': 8, 'sampling_strategy': 'all', 'learning_rate': 1.2504220093234207e-05, 'dropout_rate': 0.1901333289598338, 'batch_size': 256}. Best is trial 14 with value: 0.8945465683937073.\n",
      "[I 2024-05-16 20:56:56,729] Trial 27 finished with value: 0.9071431159973145 and parameters: {'k_neighbors': 6, 'sampling_strategy': 'auto', 'learning_rate': 0.0002819299921495315, 'dropout_rate': 0.2923592089536875, 'batch_size': 256}. Best is trial 27 with value: 0.9071431159973145.\n",
      "[I 2024-05-16 20:56:58,716] Trial 1 finished with value: 0.9023480415344238 and parameters: {'k_neighbors': 2, 'sampling_strategy': 'auto', 'learning_rate': 0.001878882239263067, 'dropout_rate': 0.265261148501506, 'batch_size': 256}. Best is trial 27 with value: 0.9071431159973145.\n",
      "[I 2024-05-16 21:06:02,003] Trial 28 finished with value: 0.8310689926147461 and parameters: {'k_neighbors': 10, 'sampling_strategy': 'minority', 'learning_rate': 0.005600871910648345, 'dropout_rate': 0.5540702518740324, 'batch_size': 64}. Best is trial 27 with value: 0.9071431159973145.\n",
      "[I 2024-05-16 21:06:28,326] Trial 8 finished with value: 0.8624272346496582 and parameters: {'k_neighbors': 2, 'sampling_strategy': 'minority', 'learning_rate': 0.0014465970798796966, 'dropout_rate': 0.43191859907897234, 'batch_size': 64}. Best is trial 27 with value: 0.9071431159973145.\n",
      "[I 2024-05-16 21:14:02,177] Trial 5 finished with value: 0.8465197682380676 and parameters: {'k_neighbors': 6, 'sampling_strategy': 'not majority', 'learning_rate': 0.0027905415009886743, 'dropout_rate': 0.3105547111390992, 'batch_size': 128}. Best is trial 27 with value: 0.9071431159973145.\n",
      "[I 2024-05-16 21:14:09,596] Trial 4 finished with value: 0.8941659927368164 and parameters: {'k_neighbors': 6, 'sampling_strategy': 'not majority', 'learning_rate': 6.73020124956395e-05, 'dropout_rate': 0.45652356955915796, 'batch_size': 128}. Best is trial 27 with value: 0.9071431159973145.\n",
      "[I 2024-05-16 21:14:12,719] Trial 10 finished with value: 0.883281946182251 and parameters: {'k_neighbors': 4, 'sampling_strategy': 'all', 'learning_rate': 0.0019251704533808497, 'dropout_rate': 0.24892611563009798, 'batch_size': 128}. Best is trial 27 with value: 0.9071431159973145.\n",
      "[I 2024-05-16 21:14:18,664] Trial 3 finished with value: 0.8920348882675171 and parameters: {'k_neighbors': 4, 'sampling_strategy': 'all', 'learning_rate': 0.00010310378307989915, 'dropout_rate': 0.5232131485951493, 'batch_size': 128}. Best is trial 27 with value: 0.9071431159973145.\n",
      "[I 2024-05-16 21:14:21,171] Trial 23 finished with value: 0.8717890381813049 and parameters: {'k_neighbors': 5, 'sampling_strategy': 'not majority', 'learning_rate': 0.010606288611221164, 'dropout_rate': 0.2629676674728154, 'batch_size': 128}. Best is trial 27 with value: 0.9071431159973145.\n",
      "[I 2024-05-16 21:14:26,638] Trial 20 finished with value: 0.8859078288078308 and parameters: {'k_neighbors': 4, 'sampling_strategy': 'not majority', 'learning_rate': 0.006173710668554133, 'dropout_rate': 0.02873842777714365, 'batch_size': 128}. Best is trial 27 with value: 0.9071431159973145.\n",
      "[I 2024-05-16 21:14:46,774] Trial 31 finished with value: 0.9123567938804626 and parameters: {'k_neighbors': 10, 'sampling_strategy': 'not majority', 'learning_rate': 0.010594467077472143, 'dropout_rate': 0.16185277449744218, 'batch_size': 128}. Best is trial 31 with value: 0.9123567938804626.\n",
      "[I 2024-05-16 21:16:35,614] Trial 35 finished with value: 0.9078661799430847 and parameters: {'k_neighbors': 4, 'sampling_strategy': 'auto', 'learning_rate': 0.00017356731618105648, 'dropout_rate': 0.12580578028118844, 'batch_size': 256}. Best is trial 31 with value: 0.9123567938804626.\n",
      "[I 2024-05-16 21:16:38,840] Trial 37 finished with value: 0.7324656248092651 and parameters: {'k_neighbors': 4, 'sampling_strategy': 'not majority', 'learning_rate': 1.4462067892772758e-05, 'dropout_rate': 0.5722182666270342, 'batch_size': 256}. Best is trial 31 with value: 0.9123567938804626.\n",
      "[I 2024-05-16 21:26:51,912] Trial 38 finished with value: 0.902233898639679 and parameters: {'k_neighbors': 5, 'sampling_strategy': 'minority', 'learning_rate': 4.1806432140902705e-05, 'dropout_rate': 0.18659980499286655, 'batch_size': 64}. Best is trial 31 with value: 0.9123567938804626.\n",
      "[I 2024-05-16 21:33:54,642] Trial 2 finished with value: 0.7698748111724854 and parameters: {'k_neighbors': 6, 'sampling_strategy': 'minority', 'learning_rate': 0.0026754796390355442, 'dropout_rate': 0.6196566501371699, 'batch_size': 32}. Best is trial 31 with value: 0.9123567938804626.\n",
      "[I 2024-05-16 21:33:58,489] Trial 29 finished with value: 0.7953343391418457 and parameters: {'k_neighbors': 9, 'sampling_strategy': 'minority', 'learning_rate': 0.03915922986440091, 'dropout_rate': 0.13601905921642424, 'batch_size': 32}. Best is trial 31 with value: 0.9123567938804626.\n",
      "[I 2024-05-16 21:34:39,612] Trial 13 finished with value: 0.8551585078239441 and parameters: {'k_neighbors': 7, 'sampling_strategy': 'minority', 'learning_rate': 0.0021338973420159395, 'dropout_rate': 0.34598311053139313, 'batch_size': 32}. Best is trial 31 with value: 0.9123567938804626.\n",
      "[I 2024-05-16 21:42:22,306] Trial 40 finished with value: 0.8570993542671204 and parameters: {'k_neighbors': 8, 'sampling_strategy': 'auto', 'learning_rate': 2.693145541760705e-05, 'dropout_rate': 0.40585614732364045, 'batch_size': 128}. Best is trial 31 with value: 0.9123567938804626.\n",
      "[I 2024-05-16 21:46:31,273] Trial 0 finished with value: 0.6554781794548035 and parameters: {'k_neighbors': 5, 'sampling_strategy': 'all', 'learning_rate': 0.015999238953076155, 'dropout_rate': 0.5640190071161619, 'batch_size': 64}. Best is trial 31 with value: 0.9123567938804626.\n",
      "[I 2024-05-16 21:46:36,545] Trial 26 finished with value: 0.8530654311180115 and parameters: {'k_neighbors': 3, 'sampling_strategy': 'auto', 'learning_rate': 0.002560164933975581, 'dropout_rate': 0.16631808251684232, 'batch_size': 64}. Best is trial 31 with value: 0.9123567938804626.\n",
      "[I 2024-05-16 21:46:41,614] Trial 18 finished with value: 0.7858964204788208 and parameters: {'k_neighbors': 2, 'sampling_strategy': 'all', 'learning_rate': 0.00103371891289838, 'dropout_rate': 0.3899519830799605, 'batch_size': 64}. Best is trial 31 with value: 0.9123567938804626.\n",
      "[I 2024-05-16 21:47:00,318] Trial 9 finished with value: 0.8861361742019653 and parameters: {'k_neighbors': 2, 'sampling_strategy': 'not majority', 'learning_rate': 0.00010570285351619775, 'dropout_rate': 0.5936004589819518, 'batch_size': 64}. Best is trial 31 with value: 0.9123567938804626.\n",
      "[I 2024-05-16 21:47:05,306] Trial 16 finished with value: 0.5154697895050049 and parameters: {'k_neighbors': 6, 'sampling_strategy': 'all', 'learning_rate': 0.038010224874452686, 'dropout_rate': 0.634839669774433, 'batch_size': 64}. Best is trial 31 with value: 0.9123567938804626.\n",
      "[I 2024-05-16 21:47:06,234] Trial 17 finished with value: 0.8837766647338867 and parameters: {'k_neighbors': 9, 'sampling_strategy': 'auto', 'learning_rate': 0.024037322546084212, 'dropout_rate': 0.006138278146365494, 'batch_size': 64}. Best is trial 31 with value: 0.9123567938804626.\n",
      "[I 2024-05-16 21:47:08,071] Trial 11 finished with value: 0.806522786617279 and parameters: {'k_neighbors': 5, 'sampling_strategy': 'all', 'learning_rate': 1.1093511791999263e-05, 'dropout_rate': 0.4080659437484595, 'batch_size': 64}. Best is trial 31 with value: 0.9123567938804626.\n",
      "[I 2024-05-16 21:49:46,000] Trial 36 finished with value: 0.8836625218391418 and parameters: {'k_neighbors': 8, 'sampling_strategy': 'minority', 'learning_rate': 3.0409689502855222e-05, 'dropout_rate': 0.09985951916226206, 'batch_size': 32}. Best is trial 31 with value: 0.9123567938804626.\n",
      "[I 2024-05-16 21:52:11,225] Trial 33 finished with value: 0.8969441056251526 and parameters: {'k_neighbors': 6, 'sampling_strategy': 'all', 'learning_rate': 7.207694591788369e-05, 'dropout_rate': 0.23262450477659694, 'batch_size': 64}. Best is trial 31 with value: 0.9123567938804626.\n",
      "[I 2024-05-16 22:24:56,157] Trial 19 finished with value: 0.7663356065750122 and parameters: {'k_neighbors': 6, 'sampling_strategy': 'all', 'learning_rate': 0.010378020937824457, 'dropout_rate': 0.40221040149173637, 'batch_size': 32}. Best is trial 31 with value: 0.9123567938804626.\n",
      "[I 2024-05-16 22:25:09,789] Trial 7 finished with value: 0.9033755660057068 and parameters: {'k_neighbors': 2, 'sampling_strategy': 'auto', 'learning_rate': 7.823898891202278e-05, 'dropout_rate': 0.34227696114927064, 'batch_size': 32}. Best is trial 31 with value: 0.9123567938804626.\n",
      "[I 2024-05-16 22:25:27,906] Trial 12 finished with value: 0.8664231300354004 and parameters: {'k_neighbors': 2, 'sampling_strategy': 'not majority', 'learning_rate': 4.159383597471238e-05, 'dropout_rate': 0.6065222350953348, 'batch_size': 32}. Best is trial 31 with value: 0.9123567938804626.\n",
      "[I 2024-05-16 22:25:29,592] Trial 30 finished with value: 0.5988507270812988 and parameters: {'k_neighbors': 8, 'sampling_strategy': 'auto', 'learning_rate': 0.05494596546532041, 'dropout_rate': 0.33740093113685554, 'batch_size': 32}. Best is trial 31 with value: 0.9123567938804626.\n",
      "[I 2024-05-16 22:25:32,231] Trial 21 finished with value: 0.8639494776725769 and parameters: {'k_neighbors': 6, 'sampling_strategy': 'auto', 'learning_rate': 0.006398505552219755, 'dropout_rate': 0.072670969410891, 'batch_size': 32}. Best is trial 31 with value: 0.9123567938804626.\n",
      "[I 2024-05-16 22:25:39,269] Trial 25 finished with value: 0.8843094706535339 and parameters: {'k_neighbors': 4, 'sampling_strategy': 'auto', 'learning_rate': 3.7148011115879156e-05, 'dropout_rate': 0.04948205988112244, 'batch_size': 32}. Best is trial 31 with value: 0.9123567938804626.\n",
      "[I 2024-05-16 22:25:50,255] Trial 15 finished with value: 0.3357308804988861 and parameters: {'k_neighbors': 2, 'sampling_strategy': 'auto', 'learning_rate': 0.06118317704559388, 'dropout_rate': 0.5766187302865827, 'batch_size': 32}. Best is trial 31 with value: 0.9123567938804626.\n",
      "[I 2024-05-16 22:31:17,771] Trial 34 finished with value: 0.8776496648788452 and parameters: {'k_neighbors': 6, 'sampling_strategy': 'auto', 'learning_rate': 2.2519922986328533e-05, 'dropout_rate': 0.29210555726748083, 'batch_size': 32}. Best is trial 31 with value: 0.9123567938804626.\n",
      "[I 2024-05-16 22:34:29,582] Trial 39 finished with value: 0.8048483729362488 and parameters: {'k_neighbors': 8, 'sampling_strategy': 'auto', 'learning_rate': 1.4354505516659691e-05, 'dropout_rate': 0.6006161644750515, 'batch_size': 32}. Best is trial 31 with value: 0.9123567938804626.\n",
      "[I 2024-05-16 22:36:24,846] Trial 42 finished with value: 0.9033375382423401 and parameters: {'k_neighbors': 2, 'sampling_strategy': 'auto', 'learning_rate': 0.00017924579324335777, 'dropout_rate': 0.05201302137587288, 'batch_size': 32}. Best is trial 31 with value: 0.9123567938804626.\n",
      "[I 2024-05-16 22:36:35,043] Trial 43 finished with value: 0.905582845211029 and parameters: {'k_neighbors': 2, 'sampling_strategy': 'auto', 'learning_rate': 0.00018405735356998948, 'dropout_rate': 0.05504763912827576, 'batch_size': 32}. Best is trial 31 with value: 0.9123567938804626.\n",
      "[I 2024-05-16 22:36:35,746] Trial 44 finished with value: 0.8869353532791138 and parameters: {'k_neighbors': 2, 'sampling_strategy': 'auto', 'learning_rate': 0.0002894700191850958, 'dropout_rate': 0.007748396175061123, 'batch_size': 32}. Best is trial 31 with value: 0.9123567938804626.\n",
      "[I 2024-05-16 22:36:37,569] Trial 45 finished with value: 0.8819880485534668 and parameters: {'k_neighbors': 2, 'sampling_strategy': 'auto', 'learning_rate': 0.0001966359371309645, 'dropout_rate': 0.05948216607610046, 'batch_size': 32}. Best is trial 31 with value: 0.9123567938804626.\n",
      "[I 2024-05-16 22:36:39,142] Trial 46 finished with value: 0.9103018045425415 and parameters: {'k_neighbors': 2, 'sampling_strategy': 'auto', 'learning_rate': 0.00033601633524256316, 'dropout_rate': 0.08128789886017818, 'batch_size': 32}. Best is trial 31 with value: 0.9123567938804626.\n",
      "[I 2024-05-16 22:36:39,726] Trial 41 finished with value: 0.8627697229385376 and parameters: {'k_neighbors': 4, 'sampling_strategy': 'auto', 'learning_rate': 0.00012353834740589802, 'dropout_rate': 0.03556810834457952, 'batch_size': 32}. Best is trial 31 with value: 0.9123567938804626.\n",
      "[I 2024-05-16 22:36:40,682] Trial 47 finished with value: 0.7687330842018127 and parameters: {'k_neighbors': 10, 'sampling_strategy': 'auto', 'learning_rate': 0.034906126628568804, 'dropout_rate': 0.06931519749819966, 'batch_size': 32}. Best is trial 31 with value: 0.9123567938804626.\n",
      "[I 2024-05-16 22:36:49,620] Trial 49 finished with value: 0.8452258706092834 and parameters: {'k_neighbors': 10, 'sampling_strategy': 'auto', 'learning_rate': 0.03257627590875706, 'dropout_rate': 0.02324503505538504, 'batch_size': 32}. Best is trial 31 with value: 0.9123567938804626.\n",
      "[I 2024-05-16 22:36:52,210] Trial 48 finished with value: 0.7345587611198425 and parameters: {'k_neighbors': 10, 'sampling_strategy': 'auto', 'learning_rate': 0.033556369863350546, 'dropout_rate': 0.05757526628726779, 'batch_size': 32}. Best is trial 31 with value: 0.9123567938804626.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m822/822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 633us/step\n",
      "--- Combined Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.91      0.92     17294\n",
      "           1       0.72      0.92      0.81      1712\n",
      "           2       0.90      0.87      0.88      1885\n",
      "           3       0.80      0.73      0.76      1937\n",
      "           4       0.58      0.75      0.65      1779\n",
      "           5       0.97      0.82      0.88      1670\n",
      "\n",
      "    accuracy                           0.87     26277\n",
      "   macro avg       0.82      0.83      0.82     26277\n",
      "weighted avg       0.89      0.87      0.88     26277\n",
      "\n",
      "--- Best Parameters for Combined Experiments ---\n",
      "{'k_neighbors': 10, 'sampling_strategy': 'not majority', 'learning_rate': 0.010594467077472143, 'dropout_rate': 0.16185277449744218, 'batch_size': 128}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'k_neighbors': 10,\n",
       "  'sampling_strategy': 'not majority',\n",
       "  'learning_rate': 0.010594467077472143,\n",
       "  'dropout_rate': 0.16185277449744218,\n",
       "  'batch_size': 128},\n",
       " <Sequential name=sequential_1, built=True>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_path = 'data'\n",
    "\n",
    "# Словарь с файлами данных\n",
    "data_files = good_datasets\n",
    "\n",
    "def build_and_train_model(X_train, y_train, X_test, y_test, trial):\n",
    "    # Настройка параметров SMOTE в Optuna\n",
    "    k_neighbors = trial.suggest_int('k_neighbors', 2, 10)\n",
    "    sampling_strategy = trial.suggest_categorical('sampling_strategy', ['auto', 'minority', 'not majority', 'all'])\n",
    "    smote = SMOTE(k_neighbors=k_neighbors, sampling_strategy=sampling_strategy, n_jobs=-1)\n",
    "    X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "    # Настройка параметров модели с помощью Optuna\n",
    "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
    "    dropout_rate = trial.suggest_uniform('dropout_rate', 0.0, 0.7)\n",
    "    batch_size = trial.suggest_categorical('batch_size', [32, 64, 128, 256])\n",
    "    epochs = 100\n",
    "    num_classes = len(np.unique(y_resampled))\n",
    "\n",
    "    # Создание модели с динамически настроенными параметрами\n",
    "    model = Sequential([\n",
    "        Dense(128, activation='relu', input_shape=(X_resampled.shape[1],)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(128, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(X_resampled, y_resampled, epochs=epochs, batch_size=batch_size, validation_split=0.2, verbose=0)\n",
    "    test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "    return test_accuracy\n",
    "\n",
    "def build_final_model(X_train, y_train, best_params):\n",
    "    # Применение SMOTE с лучшими параметрами, найденными Optuna\n",
    "    smote = SMOTE(k_neighbors=best_params['k_neighbors'], sampling_strategy=best_params['sampling_strategy'], n_jobs=-1)\n",
    "    X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "    # Построение финальной модели с использованием лучших параметров\n",
    "    model = Sequential([\n",
    "        Dense(128, activation='relu', input_shape=(X_resampled.shape[1],)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(best_params['dropout_rate']),\n",
    "        Dense(128, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(best_params['dropout_rate']),\n",
    "        Dense(len(np.unique(y_resampled)), activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=best_params['learning_rate']),\n",
    "                  loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(X_resampled, y_resampled, epochs=100, batch_size=best_params['batch_size'], validation_split=0.2, verbose=0)\n",
    "    return model\n",
    "\n",
    "def run_model(use_optuna=True):\n",
    "    all_X_train = []\n",
    "    all_y_train = []\n",
    "    all_X_test = []\n",
    "    all_y_test = []\n",
    "    \n",
    "\n",
    "    for file_name in data_files:\n",
    "        # Формирование путей доступа к данным для каждого эксперимента\n",
    "        path_palm_data = f'{base_path}/{file_name}'\n",
    "        path_protocol_data = f'{base_path}/{file_name}.protocol.csv'\n",
    "        path_meta_data = f'{base_path}/meta_information.csv'\n",
    "\n",
    "        # Загрузка и подготовка данных\n",
    "        (X_train, y_train), (X_test, y_test) = prepare_training_data(path_palm_data, path_protocol_data, path_meta_data)\n",
    "        print(f'--- Running {file_name} ---')\n",
    "        print(f'Shapes of data: {X_train.shape}, {y_train.shape}, {X_test.shape}, {y_test.shape}')\n",
    "\n",
    "        all_X_train.append(X_train)\n",
    "        all_y_train.append(y_train)\n",
    "        all_X_test.append(X_test)\n",
    "        all_y_test.append(y_test)\n",
    "\n",
    "    # Объединение данных \n",
    "    X_train = np.concatenate(all_X_train, axis=0)\n",
    "    y_train = np.concatenate(all_y_train, axis=0)\n",
    "    X_test = np.concatenate(all_X_test, axis=0)\n",
    "    y_test = np.concatenate(all_y_test, axis=0)\n",
    "    \n",
    "    print(f'--- Final shapes ---')\n",
    "    print(f'Shapes of data: {X_train.shape}, {y_train.shape}, {X_test.shape}, {y_test.shape}')\n",
    "    # Оптимизация параметров с помощью Optuna или использование предустановленных параметров\n",
    "    if use_optuna:\n",
    "        study = optuna.create_study(direction='maximize')\n",
    "        objective = lambda trial: build_and_train_model(X_train, y_train, X_test, y_test, trial)\n",
    "        study.optimize(objective, n_trials=50, n_jobs=-1)\n",
    "        best_params = study.best_trial.params\n",
    "    else:\n",
    "        best_params = {\n",
    "            'k_neighbors': 2, \n",
    "            'sampling_strategy': 'all', \n",
    "            'learning_rate': 0.00010322646860398609, \n",
    "            'dropout_rate': 0.2609382632562011, \n",
    "            'batch_size': 32\n",
    "        }\n",
    "\n",
    "    # Построение финальной модели и выполнение предсказаний\n",
    "    final_model = build_final_model(X_train, y_train, best_params)\n",
    "    y_pred = final_model.predict(X_test)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "    # Сохранение и вывод результатов классификации\n",
    "    report = classification_report(y_test, y_pred_classes)\n",
    "    print('--- Combined Classification Report ---')\n",
    "    print(report)\n",
    "    print(f'--- Best Parameters for Combined Experiments ---')\n",
    "    print(best_params)\n",
    "    return best_params, final_model\n",
    "\n",
    "run_model(use_optuna=False) # Установите `use_optuna=True`, чтобы использовать Optuna для оптимизации параметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {'k_neighbors': 10,\n",
    "  'sampling_strategy': 'not majority',\n",
    "  'learning_rate': 0.010594467077472143,\n",
    "  'dropout_rate': 0.16185277449744218,\n",
    "  'batch_size': 128}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if logistic_regression_optuna:\n",
    "#     def objective(trial):\n",
    "    \n",
    "#         # Параметры для SMOTE\n",
    "#         smote_k_neighbors = trial.suggest_int('smote_k_neighbors', 2, 15)\n",
    "#         smote_sampling_strategy = trial.suggest_categorical('smote_sampling_strategy', ['auto', 'minority', 'not majority', 'all'])\n",
    "\n",
    "#         # Параметры для логистической регрессии\n",
    "#         C = trial.suggest_loguniform('C', 1e-5, 10)\n",
    "#         max_iter = trial.suggest_int('max_iter', 1000, 10000)\n",
    "#         penalty = trial.suggest_categorical('penalty', ['l1', 'l2', 'elasticnet'])\n",
    "        \n",
    "#         # Установка совместимого решателя в зависимости от выбранной регуляризации\n",
    "#         if penalty == 'l1':\n",
    "#             solver = 'liblinear' # liblinear поддерживает только l1 и l2\n",
    "#         elif penalty == 'l2':\n",
    "#             solver = trial.suggest_categorical('solver', ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'])\n",
    "#         elif penalty == 'elasticnet':\n",
    "#             solver = 'saga'  # saga - единственный, который поддерживает elasticnet\n",
    "\n",
    "#         # Применение SMOTE\n",
    "#         smote = SMOTE(k_neighbors=smote_k_neighbors, sampling_strategy=smote_sampling_strategy)\n",
    "#         X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "#         # Обучение модели логистической регрессии\n",
    "#         model = LogisticRegression(C=C, max_iter=max_iter, penalty=penalty, solver=solver, l1_ratio=0.5 if penalty == 'elasticnet' else None)\n",
    "#         model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "#         # Оценка модели\n",
    "#         score = f1_score(\n",
    "#             y_test, \n",
    "#             model.predict(X_test), \n",
    "#             average = 'micro'\n",
    "#         )\n",
    "#         return score\n",
    "\n",
    "#     # Создание исследования\n",
    "#     study = optuna.create_study(direction='maximize')\n",
    "#     study.optimize(objective, n_trials=100, n_jobs=-1)\n",
    "\n",
    "#     print(\"Лучшие параметры:\", study.best_trial.params)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if logistic_regression_optuna:\n",
    "#     # Извлечение лучших параметров\n",
    "#     best_params = study.best_trial.params\n",
    "#     print(\"Лучшие параметры:\", best_params)\n",
    "\n",
    "#     # Применение SMOTE с лучшими параметрами\n",
    "#     smote = SMOTE(k_neighbors=best_params['smote_k_neighbors'], sampling_strategy=best_params['smote_sampling_strategy'])\n",
    "#     X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "#     # Выбор решателя в зависимости от типа регуляризации\n",
    "#     if best_params['penalty'] == 'elasticnet':\n",
    "#         solver = 'saga'  # saga - единственный решатель, поддерживающий elasticnet\n",
    "#     elif best_params['penalty'] == 'l1':\n",
    "#         solver = 'liblinear'  # liblinear - оптимальный выбор для l1 регуляризации\n",
    "#     elif best_params['penalty'] == 'l2':\n",
    "#         solver = best_params['solver'] \n",
    "#     else:  # 'none'\n",
    "#         solver = 'lbfgs'  # lbfgs хорошо подходит для отсутствия регуляризации\n",
    "\n",
    "#     # Построение и обучение модели логистической регрессии\n",
    "#     model = LogisticRegression(\n",
    "#         C=best_params['C'],\n",
    "#         max_iter=best_params['max_iter'],\n",
    "#         penalty=best_params['penalty'],\n",
    "#         solver=solver,\n",
    "#         l1_ratio=0.5 if best_params['penalty'] == 'elasticnet' else None,\n",
    "#         multi_class='auto',\n",
    "#         class_weight={0: 1, 1: 1, 2: 1, 3: 3, 4: 1, 5: 1}\n",
    "#     )\n",
    "\n",
    "#     model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "#     #Делаем предсказание класса\n",
    "#     y_pred = model.predict(X_test)\n",
    "\n",
    "#     print(f'Метрики на валидационной выборке \\n\\\n",
    "#     {classification_report(y_test, y_pred)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
