{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import optuna\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to read OMG data from a CSV file\n",
    "def read_omg_csv(path_palm_data: str, \n",
    "                 n_omg_channels: int, \n",
    "                 n_acc_channels: int = 0, \n",
    "                 n_gyr_channels: int = 0, \n",
    "                 n_mag_channels: int = 0, \n",
    "                 n_enc_channels: int = 0,\n",
    "                 button_ch: bool = True, \n",
    "                 sync_ch: bool = True, \n",
    "                 timestamp_ch: bool = True) -> pd.DataFrame:\n",
    "    \n",
    "    df_raw = pd.read_csv(path_palm_data, sep=' ', \n",
    "                         header=None, \n",
    "                         skipfooter=1, \n",
    "                         skiprows=1, \n",
    "                         engine='python')\n",
    "    columns = np.arange(n_omg_channels).astype('str').tolist()\n",
    "    \n",
    "    for label, label_count in zip(['ACC', 'GYR', 'MAG', 'ENC'], \n",
    "                                  [n_acc_channels, n_gyr_channels, n_mag_channels, n_enc_channels]):\n",
    "        columns = columns + ['{}{}'.format(label, i) for i in range(label_count)]\n",
    "        \n",
    "    if button_ch:\n",
    "        columns = columns + ['BUTTON']\n",
    "        \n",
    "    if sync_ch:\n",
    "        columns = columns + ['SYNC']\n",
    "        \n",
    "    if timestamp_ch:\n",
    "        columns = columns + ['ts']\n",
    "        \n",
    "    df_raw.columns = columns\n",
    "    \n",
    "    return df_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_training_data(path_palm_data, path_protocol_data, path_meta_data, \n",
    "                          n_omg_channels=50, n_acc_channels=3, n_gyr_channels=3, \n",
    "                          n_mag_channels=0, n_enc_channels=6, \n",
    "                          standardize=True, normalize=True,\n",
    "                          DO_REPLACE_TO_MOVING_AVERAGE=True, \n",
    "                          DO_CALCULATE_DERIVATIVE=True,\n",
    "                          DO_SHIFT_GESTURE=True,\n",
    "                          selected_channels='ALL'):\n",
    "    \"\"\"\n",
    "    Подготовка данных для обучения и тестирования из файлов данных palm, protocol и meta.\n",
    "    \n",
    "    Аргументы:\n",
    "    path_palm_data (str): Путь к файлу данных palm.\n",
    "    path_protocol_data (str): Путь к файлу данных protocol.\n",
    "    path_meta_data (str): Путь к файлу данных meta.\n",
    "    n_omg_channels, n_acc_channels, и т.д. (int): Количество каналов сенсоров.\n",
    "    standardize (bool): Если True, стандартизирует признаки.\n",
    "    normalize (bool): Если True, нормализует признаки.\n",
    "    DO_REPLACE_TO_MOVING_AVERAGE (bool): Если True, применяет скользящее среднее к данным OMG.\n",
    "    DO_CALCULATE_DERIVATIVE (bool): Если True, вычисляет производные данных OMG.\n",
    "    DO_SHIFT_GESTURE (bool): Если True, смещает целевой признак на максимальный скачок в данных.\n",
    "    selected_channels (str): Выбор каналов данных ('OMG', 'ACC_GYR', 'ALL').\n",
    "    \n",
    "    Возвращает:\n",
    "    tuple: Кортеж, содержащий данные для обучения и тестирования.\n",
    "    \"\"\"\n",
    "    # Чтение данных OMG\n",
    "    omg_data = read_omg_csv(path_palm_data, n_omg_channels, n_acc_channels, n_gyr_channels, \n",
    "                            n_mag_channels, n_enc_channels)\n",
    "    \n",
    "    # Чтение данных протокола и кодирование жестов\n",
    "    gestures_protocol = pd.read_csv(path_protocol_data)\n",
    "    le = LabelEncoder()\n",
    "    gestures_protocol['gesture'] = le.fit_transform(\n",
    "        gestures_protocol[[\n",
    "            \"Thumb\", \"Index\", \"Middle\", \"Ring\", \"Pinky\",\n",
    "            'Thumb_stretch', 'Index_stretch', 'Middle_stretch', 'Ring_stretch', 'Pinky_stretch'\n",
    "        ]].apply(lambda row: str(tuple(row)), axis=1)\n",
    "    )\n",
    "    \n",
    "    # Чтение метаинформации\n",
    "    df_meta = pd.read_csv(path_meta_data)\n",
    "    palm_file = path_palm_data.split('/')[-1]\n",
    "    last_train_idx = df_meta[df_meta['montage'] == palm_file].to_dict(orient='records')[0]['last_train_idx']\n",
    "    \n",
    "    # Синхронизация меток жестов с данными OMG, используя канал SYNC\n",
    "    y_cmd = np.array([gestures_protocol['gesture'].loc[s] for s in omg_data['SYNC'].values])\n",
    "    \n",
    "    # Подготовка названий признаков для данных OMG\n",
    "    OMG_CH = [str(i) for i in range(n_omg_channels)]\n",
    "    ACC_CH = ['ACC0', 'ACC1', 'ACC2']\n",
    "    GYR_CH = ['GYR0', 'GYR1', 'GYR2']\n",
    "    ALL_CH = OMG_CH + ACC_CH + GYR_CH\n",
    "\n",
    "    # Выбор каналов в соответствии с параметром selected_channels\n",
    "    if selected_channels == 'OMG':\n",
    "        selected_features = OMG_CH\n",
    "    elif selected_channels == 'ACC_GYR':\n",
    "        selected_features = ACC_CH + GYR_CH\n",
    "    else:\n",
    "        selected_features = ALL_CH\n",
    "    \n",
    "    if DO_REPLACE_TO_MOVING_AVERAGE:\n",
    "        # Замена на скользящее среднее\n",
    "        for col in selected_features:\n",
    "            omg_data[col] = omg_data[col].rolling(window=5).mean().bfill()\n",
    "    \n",
    "    if DO_CALCULATE_DERIVATIVE:\n",
    "        # Вычисление производных данных\n",
    "        OMG_DERIV = [f'{col}_deriv' for col in OMG_CH]\n",
    "        for col in OMG_CH:\n",
    "            omg_data[f'{col}_next'] = omg_data[col].shift(-1).ffill()\n",
    "            omg_data[f'{col}_deriv'] = omg_data[f'{col}_next'] - omg_data[col]\n",
    "        selected_features += OMG_DERIV\n",
    "\n",
    "    if DO_SHIFT_GESTURE:\n",
    "        # Смещение целевого признака\n",
    "        id_max = 0\n",
    "        cur_gesture = 0\n",
    "        for i in range(y_cmd.shape[0]):\n",
    "            if i < id_max:  # Пропускаем все значения до id_max\n",
    "                continue\n",
    "            prev_gesture = cur_gesture  # предыдущий жест\n",
    "            cur_gesture = y_cmd[i]  # текущий жест\n",
    "            if cur_gesture != prev_gesture:  # Если сменился жест\n",
    "                id_max = omg_data[OMG_DERIV][i:i+35].abs().sum(axis=1).idxmax()  # Нахождение максимального скачка\n",
    "                y_cmd[i:id_max] = prev_gesture  # Замена всех значений до id_max на предыдущий жест\n",
    "    \n",
    "    # Разделение данных на обучающие и тестовые наборы\n",
    "    X_train = omg_data[selected_features].iloc[:last_train_idx].values\n",
    "    y_train = y_cmd[:last_train_idx]\n",
    "    X_test = omg_data[selected_features].iloc[last_train_idx:].values\n",
    "    y_test = y_cmd[last_train_idx:]\n",
    "    \n",
    "    # Стандартизация и нормализация\n",
    "    if standardize:\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        \n",
    "    if normalize:\n",
    "        scaler = MinMaxScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "    \n",
    "    return (X_train, y_train), (X_test, y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Running file1 ---\n",
      "Shapes of data: (15679, 106), (15679,), (3889, 106), (3889,)\n",
      "--- Running file2 ---\n",
      "Shapes of data: (20756, 106), (20756,), (5892, 106), (5892,)\n",
      "--- Running file3 ---\n",
      "Shapes of data: (5674, 106), (5674,), (5494, 106), (5494,)\n",
      "--- Running file4 ---\n",
      "Shapes of data: (5677, 106), (5677,), (5497, 106), (5497,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-16 12:17:19,110] A new study created in memory with name: no-name-cbacaad4-47c9-44ca-a3cd-e1f59d16371b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Running file5 ---\n",
      "Shapes of data: (5690, 106), (5690,), (5505, 106), (5505,)\n",
      "--- Final shapes ---\n",
      "Shapes of data: (53476, 106), (53476,), (26277, 106), (26277,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-16 12:18:13,497] Trial 1 finished with value: 0.8871636986732483 and parameters: {'k_neighbors': 9, 'sampling_strategy': 'minority', 'learning_rate': 7.413682034745344e-05, 'dropout_rate': 0.3711992786051528, 'batch_size': 256}. Best is trial 1 with value: 0.8871636986732483.\n"
     ]
    }
   ],
   "source": [
    "base_path = 'data'\n",
    "\n",
    "# Словарь с данными по экспериментам, содержащий даты и типы файлов\n",
    "data_files = {\n",
    "    'file1': ('2023-05-31_17-14-41', 'palm'),\n",
    "    'file2': ('2023-05-05_17-57-30', 'palm'),\n",
    "    'file3': ('2023-10-25_08-52-30', 'palm'),\n",
    "    'file4': ('2023-10-18_11-16-21', 'palm'),\n",
    "    'file5': ('2023-09-29_09-20-47', 'palm')\n",
    "}\n",
    "\n",
    "def build_and_train_model(X_train, y_train, X_test, y_test, trial):\n",
    "    # Настройка параметров SMOTE в Optuna\n",
    "    k_neighbors = trial.suggest_int('k_neighbors', 2, 10)\n",
    "    sampling_strategy = trial.suggest_categorical('sampling_strategy', ['auto', 'minority', 'not majority', 'all'])\n",
    "    smote = SMOTE(k_neighbors=k_neighbors, sampling_strategy=sampling_strategy, n_jobs=-1)\n",
    "    X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "    # Настройка параметров модели с помощью Optuna\n",
    "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
    "    dropout_rate = trial.suggest_uniform('dropout_rate', 0.0, 0.7)\n",
    "    batch_size = trial.suggest_categorical('batch_size', [32, 64, 128, 256])\n",
    "    epochs = 100\n",
    "    num_classes = len(np.unique(y_resampled))\n",
    "\n",
    "    # Создание модели с динамически настроенными параметрами\n",
    "    model = Sequential([\n",
    "        Dense(128, activation='relu', input_shape=(X_resampled.shape[1],)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(128, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(X_resampled, y_resampled, epochs=epochs, batch_size=batch_size, validation_split=0.2, verbose=0)\n",
    "    test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "    return test_accuracy\n",
    "\n",
    "def build_final_model(X_train, y_train, best_params):\n",
    "    # Применение SMOTE с лучшими параметрами, найденными Optuna\n",
    "    smote = SMOTE(k_neighbors=best_params['k_neighbors'], sampling_strategy=best_params['sampling_strategy'], n_jobs=-1)\n",
    "    X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "    # Построение финальной модели с использованием лучших параметров\n",
    "    model = Sequential([\n",
    "        Dense(128, activation='relu', input_shape=(X_resampled.shape[1],)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(best_params['dropout_rate']),\n",
    "        Dense(128, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(best_params['dropout_rate']),\n",
    "        Dense(len(np.unique(y_resampled)), activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=best_params['learning_rate']),\n",
    "                  loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(X_resampled, y_resampled, epochs=100, batch_size=best_params['batch_size'], validation_split=0.2, verbose=0)\n",
    "    return model\n",
    "\n",
    "def run_model(use_optuna=True):\n",
    "    all_X_train = []\n",
    "    all_y_train = []\n",
    "    all_X_test = []\n",
    "    all_y_test = []\n",
    "    \n",
    "\n",
    "    for file_name, (date_folder, file_suffix) in data_files.items():\n",
    "        # Формирование путей доступа к данным для каждого эксперимента\n",
    "        path_palm_data = f'{base_path}/{date_folder}.{file_suffix}'\n",
    "        path_protocol_data = f'{base_path}/{date_folder}.{file_suffix}.protocol.csv'\n",
    "        path_meta_data = f'{base_path}/meta_information.csv'\n",
    "\n",
    "        # Загрузка и подготовка данных\n",
    "        (X_train, y_train), (X_test, y_test) = prepare_training_data(path_palm_data, path_protocol_data, path_meta_data)\n",
    "        print(f'--- Running {file_name} ---')\n",
    "        print(f'Shapes of data: {X_train.shape}, {y_train.shape}, {X_test.shape}, {y_test.shape}')\n",
    "\n",
    "        all_X_train.append(X_train)\n",
    "        all_y_train.append(y_train)\n",
    "        all_X_test.append(X_test)\n",
    "        all_y_test.append(y_test)\n",
    "\n",
    "    # Объединение данных после всех экспериментов\n",
    "    X_train = np.concatenate(all_X_train, axis=0)\n",
    "    y_train = np.concatenate(all_y_train, axis=0)\n",
    "    X_test = np.concatenate(all_X_test, axis=0)\n",
    "    y_test = np.concatenate(all_y_test, axis=0)\n",
    "    \n",
    "    print(f'--- Final shapes ---')\n",
    "    print(f'Shapes of data: {X_train.shape}, {y_train.shape}, {X_test.shape}, {y_test.shape}')\n",
    "    # Оптимизация параметров с помощью Optuna или использование предустановленных параметров\n",
    "    if use_optuna:\n",
    "        study = optuna.create_study(direction='maximize')\n",
    "        objective = lambda trial: build_and_train_model(X_train, y_train, X_test, y_test, trial)\n",
    "        study.optimize(objective, n_trials=50, n_jobs=-1)\n",
    "        best_params = study.best_trial.params\n",
    "    else:\n",
    "        best_params = {\n",
    "            'k_neighbors': 2, \n",
    "            'sampling_strategy': 'all', \n",
    "            'learning_rate': 0.00010322646860398609, \n",
    "            'dropout_rate': 0.2609382632562011, \n",
    "            'batch_size': 32\n",
    "        }\n",
    "\n",
    "    # Построение финальной модели и выполнение предсказаний\n",
    "    final_model = build_final_model(X_train, y_train, best_params)\n",
    "    y_pred = final_model.predict(X_test)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "    # Сохранение и вывод результатов классификации\n",
    "    report = classification_report(y_test, y_pred_classes)\n",
    "    print('--- Combined Classification Report ---')\n",
    "    print(report)\n",
    "    print(f'--- Best Parameters for Combined Experiments ---')\n",
    "    print(best_params)\n",
    "    return best_params, final_model\n",
    "\n",
    "run_model(use_optuna=True) # Установите `use_optuna=True`, чтобы использовать Optuna для оптимизации параметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if logistic_regression_optuna:\n",
    "#     def objective(trial):\n",
    "    \n",
    "#         # Параметры для SMOTE\n",
    "#         smote_k_neighbors = trial.suggest_int('smote_k_neighbors', 2, 15)\n",
    "#         smote_sampling_strategy = trial.suggest_categorical('smote_sampling_strategy', ['auto', 'minority', 'not majority', 'all'])\n",
    "\n",
    "#         # Параметры для логистической регрессии\n",
    "#         C = trial.suggest_loguniform('C', 1e-5, 10)\n",
    "#         max_iter = trial.suggest_int('max_iter', 1000, 10000)\n",
    "#         penalty = trial.suggest_categorical('penalty', ['l1', 'l2', 'elasticnet'])\n",
    "        \n",
    "#         # Установка совместимого решателя в зависимости от выбранной регуляризации\n",
    "#         if penalty == 'l1':\n",
    "#             solver = 'liblinear' # liblinear поддерживает только l1 и l2\n",
    "#         elif penalty == 'l2':\n",
    "#             solver = trial.suggest_categorical('solver', ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'])\n",
    "#         elif penalty == 'elasticnet':\n",
    "#             solver = 'saga'  # saga - единственный, который поддерживает elasticnet\n",
    "\n",
    "#         # Применение SMOTE\n",
    "#         smote = SMOTE(k_neighbors=smote_k_neighbors, sampling_strategy=smote_sampling_strategy)\n",
    "#         X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "#         # Обучение модели логистической регрессии\n",
    "#         model = LogisticRegression(C=C, max_iter=max_iter, penalty=penalty, solver=solver, l1_ratio=0.5 if penalty == 'elasticnet' else None)\n",
    "#         model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "#         # Оценка модели\n",
    "#         score = f1_score(\n",
    "#             y_test, \n",
    "#             model.predict(X_test), \n",
    "#             average = 'micro'\n",
    "#         )\n",
    "#         return score\n",
    "\n",
    "#     # Создание исследования\n",
    "#     study = optuna.create_study(direction='maximize')\n",
    "#     study.optimize(objective, n_trials=100, n_jobs=-1)\n",
    "\n",
    "#     print(\"Лучшие параметры:\", study.best_trial.params)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if logistic_regression_optuna:\n",
    "#     # Извлечение лучших параметров\n",
    "#     best_params = study.best_trial.params\n",
    "#     print(\"Лучшие параметры:\", best_params)\n",
    "\n",
    "#     # Применение SMOTE с лучшими параметрами\n",
    "#     smote = SMOTE(k_neighbors=best_params['smote_k_neighbors'], sampling_strategy=best_params['smote_sampling_strategy'])\n",
    "#     X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "#     # Выбор решателя в зависимости от типа регуляризации\n",
    "#     if best_params['penalty'] == 'elasticnet':\n",
    "#         solver = 'saga'  # saga - единственный решатель, поддерживающий elasticnet\n",
    "#     elif best_params['penalty'] == 'l1':\n",
    "#         solver = 'liblinear'  # liblinear - оптимальный выбор для l1 регуляризации\n",
    "#     elif best_params['penalty'] == 'l2':\n",
    "#         solver = best_params['solver'] \n",
    "#     else:  # 'none'\n",
    "#         solver = 'lbfgs'  # lbfgs хорошо подходит для отсутствия регуляризации\n",
    "\n",
    "#     # Построение и обучение модели логистической регрессии\n",
    "#     model = LogisticRegression(\n",
    "#         C=best_params['C'],\n",
    "#         max_iter=best_params['max_iter'],\n",
    "#         penalty=best_params['penalty'],\n",
    "#         solver=solver,\n",
    "#         l1_ratio=0.5 if best_params['penalty'] == 'elasticnet' else None,\n",
    "#         multi_class='auto',\n",
    "#         class_weight={0: 1, 1: 1, 2: 1, 3: 3, 4: 1, 5: 1}\n",
    "#     )\n",
    "\n",
    "#     model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "#     #Делаем предсказание класса\n",
    "#     y_pred = model.predict(X_test)\n",
    "\n",
    "#     print(f'Метрики на валидационной выборке \\n\\\n",
    "#     {classification_report(y_test, y_pred)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
