{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import optuna\n",
    "from sklearn.metrics import classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to read OMG data from a CSV file\n",
    "def read_omg_csv(path_palm_data: str, \n",
    "                 n_omg_channels: int, \n",
    "                 n_acc_channels: int = 0, \n",
    "                 n_gyr_channels: int = 0, \n",
    "                 n_mag_channels: int = 0, \n",
    "                 n_enc_channels: int = 0,\n",
    "                 button_ch: bool = True, \n",
    "                 sync_ch: bool = True, \n",
    "                 timestamp_ch: bool = True) -> pd.DataFrame:\n",
    "    \n",
    "    df_raw = pd.read_csv(path_palm_data, sep=' ', \n",
    "                         header=None, \n",
    "                         skipfooter=1, \n",
    "                         skiprows=1, \n",
    "                         engine='python')\n",
    "    columns = np.arange(n_omg_channels).astype('str').tolist()\n",
    "    \n",
    "    for label, label_count in zip(['ACC', 'GYR', 'MAG', 'ENC'], \n",
    "                                  [n_acc_channels, n_gyr_channels, n_mag_channels, n_enc_channels]):\n",
    "        columns = columns + ['{}{}'.format(label, i) for i in range(label_count)]\n",
    "        \n",
    "    if button_ch:\n",
    "        columns = columns + ['BUTTON']\n",
    "        \n",
    "    if sync_ch:\n",
    "        columns = columns + ['SYNC']\n",
    "        \n",
    "    if timestamp_ch:\n",
    "        columns = columns + ['ts']\n",
    "        \n",
    "    df_raw.columns = columns\n",
    "    \n",
    "    return df_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15679, 106), (15679,), (3889, 106), (3889,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def prepare_training_data(path_palm_data, path_protocol_data, path_meta_data, \n",
    "                          n_omg_channels=50, n_acc_channels=3, n_gyr_channels=3, \n",
    "                          n_mag_channels=0, n_enc_channels=6, \n",
    "                          standardize=True, normalize=True,\n",
    "                          DO_REPLACE_TO_MOVING_AVERAGE=True, \n",
    "                          DO_CALCULATE_DERIVATIVE=True,\n",
    "                          DO_SHIFT_GESTURE=True,\n",
    "                          selected_channels='ALL'):\n",
    "    \"\"\"\n",
    "    Подготовка данных для обучения и тестирования из файлов данных palm, protocol и meta.\n",
    "    \n",
    "    Аргументы:\n",
    "    path_palm_data (str): Путь к файлу данных palm.\n",
    "    path_protocol_data (str): Путь к файлу данных protocol.\n",
    "    path_meta_data (str): Путь к файлу данных meta.\n",
    "    n_omg_channels, n_acc_channels, и т.д. (int): Количество каналов сенсоров.\n",
    "    standardize (bool): Если True, стандартизирует признаки.\n",
    "    normalize (bool): Если True, нормализует признаки.\n",
    "    DO_REPLACE_TO_MOVING_AVERAGE (bool): Если True, применяет скользящее среднее к данным OMG.\n",
    "    DO_CALCULATE_DERIVATIVE (bool): Если True, вычисляет производные данных OMG.\n",
    "    DO_SHIFT_GESTURE (bool): Если True, смещает целевой признак на максимальный скачок в данных.\n",
    "    selected_channels (str): Выбор каналов данных ('OMG', 'ACC_GYR', 'ALL').\n",
    "    \n",
    "    Возвращает:\n",
    "    tuple: Кортеж, содержащий данные для обучения и тестирования.\n",
    "    \"\"\"\n",
    "    # Чтение данных OMG\n",
    "    omg_data = read_omg_csv(path_palm_data, n_omg_channels, n_acc_channels, n_gyr_channels, \n",
    "                            n_mag_channels, n_enc_channels)\n",
    "    \n",
    "    # Чтение данных протокола и кодирование жестов\n",
    "    gestures_protocol = pd.read_csv(path_protocol_data)\n",
    "    le = LabelEncoder()\n",
    "    gestures_protocol['gesture'] = le.fit_transform(\n",
    "        gestures_protocol[[\n",
    "            \"Thumb\", \"Index\", \"Middle\", \"Ring\", \"Pinky\",\n",
    "            'Thumb_stretch', 'Index_stretch', 'Middle_stretch', 'Ring_stretch', 'Pinky_stretch'\n",
    "        ]].apply(lambda row: str(tuple(row)), axis=1)\n",
    "    )\n",
    "    \n",
    "    # Чтение метаинформации\n",
    "    df_meta = pd.read_csv(path_meta_data)\n",
    "    palm_file = path_palm_data.split('/')[-1]\n",
    "    last_train_idx = df_meta[df_meta['montage'] == palm_file].to_dict(orient='records')[0]['last_train_idx']\n",
    "    \n",
    "    # Синхронизация меток жестов с данными OMG, используя канал SYNC\n",
    "    y_cmd = np.array([gestures_protocol['gesture'].loc[s] for s in omg_data['SYNC'].values])\n",
    "    \n",
    "    # Подготовка названий признаков для данных OMG\n",
    "    OMG_CH = [str(i) for i in range(n_omg_channels)]\n",
    "    ACC_CH = ['ACC0', 'ACC1', 'ACC2']\n",
    "    GYR_CH = ['GYR0', 'GYR1', 'GYR2']\n",
    "    ALL_CH = OMG_CH + ACC_CH + GYR_CH\n",
    "\n",
    "    # Выбор каналов в соответствии с параметром selected_channels\n",
    "    if selected_channels == 'OMG':\n",
    "        selected_features = OMG_CH\n",
    "    elif selected_channels == 'ACC_GYR':\n",
    "        selected_features = ACC_CH + GYR_CH\n",
    "    else:\n",
    "        selected_features = ALL_CH\n",
    "    \n",
    "    if DO_REPLACE_TO_MOVING_AVERAGE:\n",
    "        # Замена на скользящее среднее\n",
    "        for col in selected_features:\n",
    "            omg_data[col] = omg_data[col].rolling(window=5).mean().bfill()\n",
    "    \n",
    "    if DO_CALCULATE_DERIVATIVE:\n",
    "        # Вычисление производных данных\n",
    "        OMG_DERIV = [f'{col}_deriv' for col in OMG_CH]\n",
    "        for col in OMG_CH:\n",
    "            omg_data[f'{col}_next'] = omg_data[col].shift(-1).ffill()\n",
    "            omg_data[f'{col}_deriv'] = omg_data[f'{col}_next'] - omg_data[col]\n",
    "        selected_features += OMG_DERIV\n",
    "\n",
    "    if DO_SHIFT_GESTURE:\n",
    "        # Смещение целевого признака\n",
    "        id_max = 0\n",
    "        cur_gesture = 0\n",
    "        for i in range(y_cmd.shape[0]):\n",
    "            if i < id_max:  # Пропускаем все значения до id_max\n",
    "                continue\n",
    "            prev_gesture = cur_gesture  # предыдущий жест\n",
    "            cur_gesture = y_cmd[i]  # текущий жест\n",
    "            if cur_gesture != prev_gesture:  # Если сменился жест\n",
    "                id_max = omg_data[OMG_DERIV][i:i+35].abs().sum(axis=1).idxmax()  # Нахождение максимального скачка\n",
    "                y_cmd[i:id_max] = prev_gesture  # Замена всех значений до id_max на предыдущий жест\n",
    "    \n",
    "    # Разделение данных на обучающие и тестовые наборы\n",
    "    X_train = omg_data[selected_features].iloc[:last_train_idx].values\n",
    "    y_train = y_cmd[:last_train_idx]\n",
    "    X_test = omg_data[selected_features].iloc[last_train_idx:].values\n",
    "    y_test = y_cmd[last_train_idx:]\n",
    "    \n",
    "    # Стандартизация и нормализация\n",
    "    if standardize:\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        \n",
    "    if normalize:\n",
    "        scaler = MinMaxScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "    \n",
    "    return (X_train, y_train), (X_test, y_test)\n",
    "\n",
    "path_palm_data = 'data/2023-05-31_17-14-41.palm'\n",
    "path_protocol_data = 'data/2023-05-31_17-14-41.palm.protocol.csv'\n",
    "path_meta_data = 'data/meta_information.csv'\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = prepare_training_data(path_palm_data, path_protocol_data, path_meta_data, standardize=True, normalize=False)\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Counter({0: 10677, 5: 1052, 3: 1032, 4: 1020, 1: 952, 2: 946}),\n",
       " Counter({0: 2608, 2: 279, 5: 258, 3: 252, 1: 246, 4: 246}))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Посчитаем, как распределены классы\n",
    "class_counts_train = Counter(y_train)\n",
    "class_counts_test = Counter(y_test)\n",
    "\n",
    "class_counts_train, class_counts_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видно, классы не сбалансированы: класс 0 значительно превосходит по количеству остальные классы в обоих наборах данных. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-08 00:43:39,280] A new study created in memory with name: no-name-b15306b1-da03-4596-b85d-7a35a219e295\n",
      "[I 2024-05-08 00:46:49,508] Trial 5 finished with value: 0.9539727568626404 and parameters: {'k_neighbors': 2, 'sampling_strategy': 'minority', 'learning_rate': 0.01982122185948804, 'dropout_rate': 0.5090900689155323, 'batch_size': 256}. Best is trial 5 with value: 0.9539727568626404.\n",
      "[I 2024-05-08 00:46:49,628] Trial 16 finished with value: 0.9467729330062866 and parameters: {'k_neighbors': 5, 'sampling_strategy': 'minority', 'learning_rate': 0.024714079703419097, 'dropout_rate': 0.3626732840077775, 'batch_size': 256}. Best is trial 5 with value: 0.9539727568626404.\n",
      "[I 2024-05-08 00:46:53,839] Trial 25 finished with value: 0.8729750514030457 and parameters: {'k_neighbors': 6, 'sampling_strategy': 'minority', 'learning_rate': 1.6121909114619943e-05, 'dropout_rate': 0.4882716037312229, 'batch_size': 256}. Best is trial 5 with value: 0.9539727568626404.\n",
      "[I 2024-05-08 00:48:48,239] Trial 20 finished with value: 0.9506300091743469 and parameters: {'k_neighbors': 8, 'sampling_strategy': 'minority', 'learning_rate': 0.0013641226186525733, 'dropout_rate': 0.6528114487279162, 'batch_size': 128}. Best is trial 5 with value: 0.9539727568626404.\n",
      "[I 2024-05-08 00:49:55,314] Trial 34 finished with value: 0.9478014707565308 and parameters: {'k_neighbors': 9, 'sampling_strategy': 'minority', 'learning_rate': 0.013654433124075464, 'dropout_rate': 0.4592882411714587, 'batch_size': 256}. Best is trial 5 with value: 0.9539727568626404.\n",
      "[I 2024-05-08 00:50:07,702] Trial 3 finished with value: 0.9447158575057983 and parameters: {'k_neighbors': 6, 'sampling_strategy': 'all', 'learning_rate': 0.00011623210895906515, 'dropout_rate': 0.5236510901336126, 'batch_size': 256}. Best is trial 5 with value: 0.9539727568626404.\n",
      "[I 2024-05-08 00:50:08,530] Trial 8 finished with value: 0.9434301853179932 and parameters: {'k_neighbors': 7, 'sampling_strategy': 'auto', 'learning_rate': 0.0003427265823450337, 'dropout_rate': 0.47712427152761533, 'batch_size': 256}. Best is trial 5 with value: 0.9539727568626404.\n",
      "[I 2024-05-08 00:50:10,512] Trial 10 finished with value: 0.9447158575057983 and parameters: {'k_neighbors': 6, 'sampling_strategy': 'auto', 'learning_rate': 0.0007553828231035373, 'dropout_rate': 0.5788038010398759, 'batch_size': 256}. Best is trial 5 with value: 0.9539727568626404.\n",
      "[I 2024-05-08 00:50:14,168] Trial 18 finished with value: 0.949344277381897 and parameters: {'k_neighbors': 3, 'sampling_strategy': 'all', 'learning_rate': 0.0031395829473824795, 'dropout_rate': 0.670529128242124, 'batch_size': 256}. Best is trial 5 with value: 0.9539727568626404.\n",
      "[I 2024-05-08 00:50:14,708] Trial 13 finished with value: 0.9313448071479797 and parameters: {'k_neighbors': 9, 'sampling_strategy': 'auto', 'learning_rate': 0.019644243383676575, 'dropout_rate': 0.05972438823101431, 'batch_size': 256}. Best is trial 5 with value: 0.9539727568626404.\n",
      "[I 2024-05-08 00:50:17,749] Trial 28 finished with value: 0.9439444541931152 and parameters: {'k_neighbors': 7, 'sampling_strategy': 'all', 'learning_rate': 0.0017496128388106102, 'dropout_rate': 0.1671404969648634, 'batch_size': 256}. Best is trial 5 with value: 0.9539727568626404.\n",
      "[I 2024-05-08 00:50:18,627] Trial 21 finished with value: 0.9436873197555542 and parameters: {'k_neighbors': 3, 'sampling_strategy': 'not majority', 'learning_rate': 0.0035150499030314653, 'dropout_rate': 0.25563642505082773, 'batch_size': 256}. Best is trial 5 with value: 0.9539727568626404.\n",
      "[I 2024-05-08 00:50:19,227] Trial 31 finished with value: 0.9447158575057983 and parameters: {'k_neighbors': 9, 'sampling_strategy': 'auto', 'learning_rate': 0.05554309885486366, 'dropout_rate': 0.5794272684844127, 'batch_size': 256}. Best is trial 5 with value: 0.9539727568626404.\n",
      "[I 2024-05-08 00:50:21,471] Trial 29 finished with value: 0.9472872018814087 and parameters: {'k_neighbors': 7, 'sampling_strategy': 'all', 'learning_rate': 0.000467655827083349, 'dropout_rate': 0.04792305386410808, 'batch_size': 256}. Best is trial 5 with value: 0.9539727568626404.\n",
      "[I 2024-05-08 00:50:24,161] Trial 23 finished with value: 0.9359732866287231 and parameters: {'k_neighbors': 9, 'sampling_strategy': 'auto', 'learning_rate': 0.0065471797361428465, 'dropout_rate': 0.28329304394147886, 'batch_size': 256}. Best is trial 5 with value: 0.9539727568626404.\n",
      "[I 2024-05-08 00:53:12,270] Trial 40 finished with value: 0.9490871429443359 and parameters: {'k_neighbors': 10, 'sampling_strategy': 'minority', 'learning_rate': 0.0009173540317227318, 'dropout_rate': 0.04462997624983774, 'batch_size': 256}. Best is trial 5 with value: 0.9539727568626404.\n",
      "[I 2024-05-08 00:53:15,121] Trial 33 finished with value: 0.9506300091743469 and parameters: {'k_neighbors': 9, 'sampling_strategy': 'not majority', 'learning_rate': 3.4054422045048245e-05, 'dropout_rate': 0.24505627516595593, 'batch_size': 256}. Best is trial 5 with value: 0.9539727568626404.\n",
      "[I 2024-05-08 00:55:15,170] Trial 44 finished with value: 0.926202118396759 and parameters: {'k_neighbors': 2, 'sampling_strategy': 'minority', 'learning_rate': 9.593578059736714e-05, 'dropout_rate': 0.6858758014365988, 'batch_size': 128}. Best is trial 5 with value: 0.9539727568626404.\n",
      "[I 2024-05-08 00:55:17,240] Trial 6 finished with value: 0.9339161515235901 and parameters: {'k_neighbors': 6, 'sampling_strategy': 'auto', 'learning_rate': 1.559014669660127e-05, 'dropout_rate': 0.63207108417943, 'batch_size': 128}. Best is trial 5 with value: 0.9539727568626404.\n",
      "[I 2024-05-08 00:55:19,126] Trial 14 finished with value: 0.9475443363189697 and parameters: {'k_neighbors': 4, 'sampling_strategy': 'not majority', 'learning_rate': 0.00409806278871278, 'dropout_rate': 0.5841572637481646, 'batch_size': 128}. Best is trial 5 with value: 0.9539727568626404.\n",
      "[I 2024-05-08 00:55:19,195] Trial 43 finished with value: 0.9462586641311646 and parameters: {'k_neighbors': 2, 'sampling_strategy': 'minority', 'learning_rate': 0.09946850754935299, 'dropout_rate': 0.6955939733642905, 'batch_size': 128}. Best is trial 5 with value: 0.9539727568626404.\n",
      "[I 2024-05-08 00:55:21,323] Trial 19 finished with value: 0.9416302442550659 and parameters: {'k_neighbors': 7, 'sampling_strategy': 'auto', 'learning_rate': 1.2415842505972565e-05, 'dropout_rate': 0.488701943513363, 'batch_size': 128}. Best is trial 5 with value: 0.9539727568626404.\n",
      "[I 2024-05-08 00:55:21,645] Trial 22 finished with value: 0.9439444541931152 and parameters: {'k_neighbors': 4, 'sampling_strategy': 'all', 'learning_rate': 1.5953423086905094e-05, 'dropout_rate': 0.028799495097485604, 'batch_size': 128}. Best is trial 5 with value: 0.9539727568626404.\n",
      "[I 2024-05-08 00:55:21,704] Trial 15 finished with value: 0.9470300674438477 and parameters: {'k_neighbors': 10, 'sampling_strategy': 'all', 'learning_rate': 0.00017926874471577866, 'dropout_rate': 0.45811583962336655, 'batch_size': 128}. Best is trial 5 with value: 0.9539727568626404.\n",
      "[I 2024-05-08 00:55:22,857] Trial 45 finished with value: 0.9506300091743469 and parameters: {'k_neighbors': 2, 'sampling_strategy': 'minority', 'learning_rate': 0.007532017117675603, 'dropout_rate': 0.691056275532393, 'batch_size': 128}. Best is trial 5 with value: 0.9539727568626404.\n",
      "[I 2024-05-08 00:55:23,411] Trial 24 finished with value: 0.9442015886306763 and parameters: {'k_neighbors': 7, 'sampling_strategy': 'all', 'learning_rate': 2.194931041168686e-05, 'dropout_rate': 0.6061334777500041, 'batch_size': 128}. Best is trial 5 with value: 0.9539727568626404.\n",
      "[I 2024-05-08 00:55:25,624] Trial 46 finished with value: 0.9452301263809204 and parameters: {'k_neighbors': 2, 'sampling_strategy': 'minority', 'learning_rate': 0.08527666065415375, 'dropout_rate': 0.6776851243683168, 'batch_size': 128}. Best is trial 5 with value: 0.9539727568626404.\n",
      "[I 2024-05-08 00:55:26,197] Trial 30 finished with value: 0.9488300085067749 and parameters: {'k_neighbors': 8, 'sampling_strategy': 'all', 'learning_rate': 0.000430230767041149, 'dropout_rate': 0.4667918180786837, 'batch_size': 128}. Best is trial 5 with value: 0.9539727568626404.\n",
      "[I 2024-05-08 00:57:16,291] Trial 47 finished with value: 0.9516585469245911 and parameters: {'k_neighbors': 2, 'sampling_strategy': 'minority', 'learning_rate': 0.07225288296304473, 'dropout_rate': 0.6466180907659412, 'batch_size': 128}. Best is trial 5 with value: 0.9539727568626404.\n",
      "[I 2024-05-08 00:57:18,771] Trial 48 finished with value: 0.95140141248703 and parameters: {'k_neighbors': 2, 'sampling_strategy': 'minority', 'learning_rate': 0.08707188235767604, 'dropout_rate': 0.684184288233252, 'batch_size': 128}. Best is trial 5 with value: 0.9539727568626404.\n",
      "[I 2024-05-08 00:57:25,176] Trial 32 finished with value: 0.9526870846748352 and parameters: {'k_neighbors': 3, 'sampling_strategy': 'all', 'learning_rate': 0.00047626682887409337, 'dropout_rate': 0.625053108505282, 'batch_size': 128}. Best is trial 5 with value: 0.9539727568626404.\n",
      "[I 2024-05-08 00:58:31,686] Trial 35 finished with value: 0.942144513130188 and parameters: {'k_neighbors': 4, 'sampling_strategy': 'all', 'learning_rate': 0.016059671696165113, 'dropout_rate': 0.32121018857130196, 'batch_size': 128}. Best is trial 5 with value: 0.9539727568626404.\n",
      "[I 2024-05-08 00:58:42,206] Trial 7 finished with value: 0.9467729330062866 and parameters: {'k_neighbors': 4, 'sampling_strategy': 'minority', 'learning_rate': 0.00023176545721411137, 'dropout_rate': 0.013293326126345017, 'batch_size': 32}. Best is trial 5 with value: 0.9539727568626404.\n",
      "[I 2024-05-08 00:58:47,447] Trial 2 finished with value: 0.9408588409423828 and parameters: {'k_neighbors': 4, 'sampling_strategy': 'minority', 'learning_rate': 4.333037664341737e-05, 'dropout_rate': 0.026475552300491464, 'batch_size': 32}. Best is trial 5 with value: 0.9539727568626404.\n",
      "[I 2024-05-08 00:59:04,966] Trial 36 finished with value: 0.9483157396316528 and parameters: {'k_neighbors': 6, 'sampling_strategy': 'not majority', 'learning_rate': 0.0016112577518423627, 'dropout_rate': 0.40625991842272235, 'batch_size': 128}. Best is trial 5 with value: 0.9539727568626404.\n",
      "[I 2024-05-08 00:59:06,130] Trial 17 finished with value: 0.9485728740692139 and parameters: {'k_neighbors': 9, 'sampling_strategy': 'minority', 'learning_rate': 0.027081621551940667, 'dropout_rate': 0.019159625481411556, 'batch_size': 32}. Best is trial 5 with value: 0.9539727568626404.\n",
      "[I 2024-05-08 00:59:07,657] Trial 38 finished with value: 0.9372589588165283 and parameters: {'k_neighbors': 3, 'sampling_strategy': 'all', 'learning_rate': 0.08834517936124445, 'dropout_rate': 0.1418953985832138, 'batch_size': 128}. Best is trial 5 with value: 0.9539727568626404.\n",
      "[I 2024-05-08 00:59:11,929] Trial 42 finished with value: 0.9452301263809204 and parameters: {'k_neighbors': 2, 'sampling_strategy': 'not majority', 'learning_rate': 0.06533087842077111, 'dropout_rate': 0.6809918841685272, 'batch_size': 128}. Best is trial 5 with value: 0.9539727568626404.\n",
      "[I 2024-05-08 01:00:36,452] Trial 1 finished with value: 0.9400874376296997 and parameters: {'k_neighbors': 9, 'sampling_strategy': 'all', 'learning_rate': 0.06060812989123799, 'dropout_rate': 0.2355057474839913, 'batch_size': 64}. Best is trial 5 with value: 0.9539727568626404.\n",
      "[I 2024-05-08 01:00:38,551] Trial 4 finished with value: 0.9411159753799438 and parameters: {'k_neighbors': 10, 'sampling_strategy': 'auto', 'learning_rate': 0.0029719092059267505, 'dropout_rate': 0.24664150877990032, 'batch_size': 64}. Best is trial 5 with value: 0.9539727568626404.\n",
      "[I 2024-05-08 01:02:26,373] Trial 49 finished with value: 0.9442015886306763 and parameters: {'k_neighbors': 4, 'sampling_strategy': 'minority', 'learning_rate': 0.09036495449698198, 'dropout_rate': 0.3727956108416507, 'batch_size': 32}. Best is trial 5 with value: 0.9539727568626404.\n",
      "[I 2024-05-08 01:05:46,941] Trial 12 finished with value: 0.9447158575057983 and parameters: {'k_neighbors': 6, 'sampling_strategy': 'all', 'learning_rate': 0.020872868565827978, 'dropout_rate': 0.24003654575299757, 'batch_size': 32}. Best is trial 5 with value: 0.9539727568626404.\n",
      "[I 2024-05-08 01:05:48,422] Trial 11 finished with value: 0.9475443363189697 and parameters: {'k_neighbors': 7, 'sampling_strategy': 'not majority', 'learning_rate': 8.371598042503273e-05, 'dropout_rate': 0.4710398905205787, 'batch_size': 32}. Best is trial 5 with value: 0.9539727568626404.\n",
      "[I 2024-05-08 01:05:48,813] Trial 0 finished with value: 0.9490871429443359 and parameters: {'k_neighbors': 10, 'sampling_strategy': 'not majority', 'learning_rate': 0.0002422068488621805, 'dropout_rate': 0.449546144859638, 'batch_size': 32}. Best is trial 5 with value: 0.9539727568626404.\n",
      "[I 2024-05-08 01:05:49,365] Trial 26 finished with value: 0.951144278049469 and parameters: {'k_neighbors': 9, 'sampling_strategy': 'all', 'learning_rate': 0.0024099335096636684, 'dropout_rate': 0.014795885047155675, 'batch_size': 32}. Best is trial 5 with value: 0.9539727568626404.\n",
      "[I 2024-05-08 01:05:49,441] Trial 9 finished with value: 0.9447158575057983 and parameters: {'k_neighbors': 10, 'sampling_strategy': 'not majority', 'learning_rate': 0.012370924444756506, 'dropout_rate': 0.49281643251803564, 'batch_size': 32}. Best is trial 5 with value: 0.9539727568626404.\n",
      "[I 2024-05-08 01:05:51,439] Trial 27 finished with value: 0.9501157402992249 and parameters: {'k_neighbors': 2, 'sampling_strategy': 'all', 'learning_rate': 2.9744247473024043e-05, 'dropout_rate': 0.6722514902098012, 'batch_size': 32}. Best is trial 5 with value: 0.9539727568626404.\n",
      "[I 2024-05-08 01:06:21,161] Trial 39 finished with value: 0.9416302442550659 and parameters: {'k_neighbors': 10, 'sampling_strategy': 'auto', 'learning_rate': 0.015839446183672647, 'dropout_rate': 0.040780673130351636, 'batch_size': 32}. Best is trial 5 with value: 0.9539727568626404.\n",
      "[I 2024-05-08 01:06:21,726] Trial 37 finished with value: 0.9506300091743469 and parameters: {'k_neighbors': 9, 'sampling_strategy': 'auto', 'learning_rate': 0.00034013357071950047, 'dropout_rate': 0.32580538921548485, 'batch_size': 32}. Best is trial 5 with value: 0.9539727568626404.\n",
      "[I 2024-05-08 01:06:22,283] Trial 41 finished with value: 0.9411159753799438 and parameters: {'k_neighbors': 2, 'sampling_strategy': 'not majority', 'learning_rate': 0.05031442071354815, 'dropout_rate': 0.19085623189910095, 'batch_size': 32}. Best is trial 5 with value: 0.9539727568626404.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие параметры:\n",
      "FrozenTrial(number=5, state=TrialState.COMPLETE, values=[0.9539727568626404], datetime_start=datetime.datetime(2024, 5, 8, 0, 43, 39, 287665), datetime_complete=datetime.datetime(2024, 5, 8, 0, 46, 49, 508467), params={'k_neighbors': 2, 'sampling_strategy': 'minority', 'learning_rate': 0.01982122185948804, 'dropout_rate': 0.5090900689155323, 'batch_size': 256}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'k_neighbors': IntDistribution(high=10, log=False, low=2, step=1), 'sampling_strategy': CategoricalDistribution(choices=('auto', 'minority', 'not majority', 'all')), 'learning_rate': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'dropout_rate': FloatDistribution(high=0.7, log=False, low=0.0, step=None), 'batch_size': CategoricalDistribution(choices=(32, 64, 128, 256))}, trial_id=5, value=None)\n"
     ]
    }
   ],
   "source": [
    "def build_and_train_model(X_train, y_train, X_test, y_test, trial):\n",
    "    # Параметры для SMOTE\n",
    "    k_neighbors = trial.suggest_int('k_neighbors', 2, 10)\n",
    "    sampling_strategy = trial.suggest_categorical('sampling_strategy', ['auto', 'minority', 'not majority', 'all'])\n",
    "    \n",
    "    # Применяем SMOTE\n",
    "    smote = SMOTE(k_neighbors=k_neighbors, sampling_strategy=sampling_strategy, n_jobs=-1)\n",
    "    X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Параметры модели\n",
    "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
    "    dropout_rate = trial.suggest_uniform('dropout_rate', 0.0, 0.7)\n",
    "    batch_size = trial.suggest_categorical('batch_size', [32, 64, 128, 256])\n",
    "    epochs = 100\n",
    "\n",
    "    num_classes = len(np.unique(y_resampled))\n",
    "    \n",
    "    # Создание модели\n",
    "    model = Sequential([\n",
    "        Dense(128, activation='relu', input_shape=(X_resampled.shape[1],)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(128, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    # Компиляция модели\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # Обучение модели\n",
    "    history = model.fit(X_resampled, y_resampled, epochs=epochs, batch_size=batch_size, validation_split=0.2, verbose=0)\n",
    "    \n",
    "    # Оценка модели\n",
    "    test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "    return test_accuracy\n",
    "\n",
    "def objective(trial):\n",
    "    return build_and_train_model(X_train, y_train, X_test, y_test, trial)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50, n_jobs=-1)\n",
    "\n",
    "print(\"Лучшие параметры:\")\n",
    "print(study.best_trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие параметры: {'k_neighbors': 2, 'sampling_strategy': 'minority', 'learning_rate': 0.01982122185948804, 'dropout_rate': 0.5090900689155323, 'batch_size': 256}\n",
      "Epoch 1/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7526 - loss: 0.8125 - val_accuracy: 1.0000 - val_loss: 4.7103e-04\n",
      "Epoch 2/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9276 - loss: 0.2153 - val_accuracy: 1.0000 - val_loss: 2.0746e-04\n",
      "Epoch 3/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9480 - loss: 0.1516 - val_accuracy: 1.0000 - val_loss: 0.0014\n",
      "Epoch 4/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9580 - loss: 0.1239 - val_accuracy: 1.0000 - val_loss: 1.3437e-04\n",
      "Epoch 5/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9651 - loss: 0.1104 - val_accuracy: 1.0000 - val_loss: 5.5533e-04\n",
      "Epoch 6/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9689 - loss: 0.0951 - val_accuracy: 1.0000 - val_loss: 3.2083e-04\n",
      "Epoch 7/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9751 - loss: 0.0782 - val_accuracy: 1.0000 - val_loss: 2.7775e-04\n",
      "Epoch 8/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9728 - loss: 0.0810 - val_accuracy: 1.0000 - val_loss: 2.7365e-04\n",
      "Epoch 9/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9777 - loss: 0.0693 - val_accuracy: 0.9992 - val_loss: 0.0024\n",
      "Epoch 10/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9765 - loss: 0.0749 - val_accuracy: 1.0000 - val_loss: 1.2393e-04\n",
      "Epoch 11/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9795 - loss: 0.0610 - val_accuracy: 1.0000 - val_loss: 4.8481e-05\n",
      "Epoch 12/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9814 - loss: 0.0547 - val_accuracy: 1.0000 - val_loss: 1.0667e-04\n",
      "Epoch 13/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9787 - loss: 0.0623 - val_accuracy: 1.0000 - val_loss: 3.4393e-04\n",
      "Epoch 14/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9767 - loss: 0.0689 - val_accuracy: 0.9994 - val_loss: 0.0012\n",
      "Epoch 15/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9804 - loss: 0.0573 - val_accuracy: 1.0000 - val_loss: 5.3857e-06\n",
      "Epoch 16/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9807 - loss: 0.0619 - val_accuracy: 1.0000 - val_loss: 2.0248e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9801 - loss: 0.0571 - val_accuracy: 0.9998 - val_loss: 2.5183e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9823 - loss: 0.0527 - val_accuracy: 1.0000 - val_loss: 2.0991e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9818 - loss: 0.0543 - val_accuracy: 1.0000 - val_loss: 1.5836e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9812 - loss: 0.0546 - val_accuracy: 1.0000 - val_loss: 2.2929e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9837 - loss: 0.0447 - val_accuracy: 1.0000 - val_loss: 9.2848e-05\n",
      "Epoch 22/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9826 - loss: 0.0542 - val_accuracy: 1.0000 - val_loss: 5.4682e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9866 - loss: 0.0435 - val_accuracy: 1.0000 - val_loss: 9.4837e-06\n",
      "Epoch 24/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9866 - loss: 0.0468 - val_accuracy: 1.0000 - val_loss: 1.9767e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9838 - loss: 0.0472 - val_accuracy: 1.0000 - val_loss: 2.8759e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9827 - loss: 0.0510 - val_accuracy: 0.9998 - val_loss: 4.1208e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9837 - loss: 0.0494 - val_accuracy: 1.0000 - val_loss: 6.9499e-05\n",
      "Epoch 28/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9852 - loss: 0.0412 - val_accuracy: 1.0000 - val_loss: 1.3943e-05\n",
      "Epoch 29/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9857 - loss: 0.0423 - val_accuracy: 1.0000 - val_loss: 7.0369e-05\n",
      "Epoch 30/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9857 - loss: 0.0467 - val_accuracy: 1.0000 - val_loss: 8.8121e-05\n",
      "Epoch 31/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9841 - loss: 0.0444 - val_accuracy: 0.9998 - val_loss: 7.0292e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9839 - loss: 0.0514 - val_accuracy: 1.0000 - val_loss: 8.0502e-05\n",
      "Epoch 33/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9853 - loss: 0.0429 - val_accuracy: 0.9998 - val_loss: 5.7876e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9863 - loss: 0.0440 - val_accuracy: 0.9998 - val_loss: 7.7486e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9855 - loss: 0.0394 - val_accuracy: 1.0000 - val_loss: 1.0036e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9855 - loss: 0.0482 - val_accuracy: 1.0000 - val_loss: 5.2797e-07\n",
      "Epoch 37/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9866 - loss: 0.0378 - val_accuracy: 0.9996 - val_loss: 4.7739e-04\n",
      "Epoch 38/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9863 - loss: 0.0426 - val_accuracy: 1.0000 - val_loss: 1.0983e-04\n",
      "Epoch 39/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9873 - loss: 0.0408 - val_accuracy: 1.0000 - val_loss: 4.3867e-06\n",
      "Epoch 40/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9847 - loss: 0.0442 - val_accuracy: 1.0000 - val_loss: 2.6609e-05\n",
      "Epoch 41/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9885 - loss: 0.0361 - val_accuracy: 0.9998 - val_loss: 5.1682e-04\n",
      "Epoch 42/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9872 - loss: 0.0397 - val_accuracy: 0.9998 - val_loss: 3.1514e-04\n",
      "Epoch 43/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9871 - loss: 0.0385 - val_accuracy: 1.0000 - val_loss: 5.3280e-07\n",
      "Epoch 44/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9879 - loss: 0.0423 - val_accuracy: 1.0000 - val_loss: 1.4277e-05\n",
      "Epoch 45/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9868 - loss: 0.0431 - val_accuracy: 1.0000 - val_loss: 1.0477e-04\n",
      "Epoch 46/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9890 - loss: 0.0384 - val_accuracy: 1.0000 - val_loss: 5.7699e-04\n",
      "Epoch 47/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9877 - loss: 0.0381 - val_accuracy: 1.0000 - val_loss: 2.6639e-05\n",
      "Epoch 48/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9900 - loss: 0.0304 - val_accuracy: 1.0000 - val_loss: 1.3775e-04\n",
      "Epoch 49/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9874 - loss: 0.0440 - val_accuracy: 1.0000 - val_loss: 1.2281e-05\n",
      "Epoch 50/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9894 - loss: 0.0334 - val_accuracy: 1.0000 - val_loss: 3.7685e-05\n",
      "Epoch 51/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9898 - loss: 0.0333 - val_accuracy: 0.9998 - val_loss: 3.5405e-04\n",
      "Epoch 52/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9889 - loss: 0.0326 - val_accuracy: 1.0000 - val_loss: 1.3654e-05\n",
      "Epoch 53/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9902 - loss: 0.0294 - val_accuracy: 1.0000 - val_loss: 6.7650e-06\n",
      "Epoch 54/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9894 - loss: 0.0327 - val_accuracy: 0.9994 - val_loss: 0.0028\n",
      "Epoch 55/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9904 - loss: 0.0328 - val_accuracy: 0.9998 - val_loss: 1.8702e-04\n",
      "Epoch 56/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9899 - loss: 0.0309 - val_accuracy: 0.9996 - val_loss: 9.7215e-04\n",
      "Epoch 57/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9877 - loss: 0.0350 - val_accuracy: 1.0000 - val_loss: 1.1609e-05\n",
      "Epoch 58/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9885 - loss: 0.0375 - val_accuracy: 0.9996 - val_loss: 8.5022e-04\n",
      "Epoch 59/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9869 - loss: 0.0379 - val_accuracy: 1.0000 - val_loss: 4.7531e-05\n",
      "Epoch 60/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9893 - loss: 0.0301 - val_accuracy: 1.0000 - val_loss: 1.6713e-05\n",
      "Epoch 61/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9901 - loss: 0.0335 - val_accuracy: 1.0000 - val_loss: 1.0593e-05\n",
      "Epoch 62/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9910 - loss: 0.0282 - val_accuracy: 0.9998 - val_loss: 4.9087e-04\n",
      "Epoch 63/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9898 - loss: 0.0314 - val_accuracy: 1.0000 - val_loss: 7.5739e-06\n",
      "Epoch 64/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9918 - loss: 0.0243 - val_accuracy: 1.0000 - val_loss: 4.1042e-05\n",
      "Epoch 65/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9913 - loss: 0.0289 - val_accuracy: 1.0000 - val_loss: 6.1700e-05\n",
      "Epoch 66/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9875 - loss: 0.0430 - val_accuracy: 1.0000 - val_loss: 8.0616e-05\n",
      "Epoch 67/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9900 - loss: 0.0275 - val_accuracy: 1.0000 - val_loss: 1.1052e-06\n",
      "Epoch 68/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9886 - loss: 0.0376 - val_accuracy: 1.0000 - val_loss: 1.1915e-06\n",
      "Epoch 69/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9885 - loss: 0.0365 - val_accuracy: 1.0000 - val_loss: 2.4094e-06\n",
      "Epoch 70/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9885 - loss: 0.0343 - val_accuracy: 1.0000 - val_loss: 1.2764e-05\n",
      "Epoch 71/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9881 - loss: 0.0380 - val_accuracy: 0.9998 - val_loss: 6.6836e-04\n",
      "Epoch 72/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9897 - loss: 0.0330 - val_accuracy: 1.0000 - val_loss: 5.5125e-05\n",
      "Epoch 73/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9912 - loss: 0.0286 - val_accuracy: 1.0000 - val_loss: 4.2450e-07\n",
      "Epoch 74/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9905 - loss: 0.0315 - val_accuracy: 1.0000 - val_loss: 5.1352e-05\n",
      "Epoch 75/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9898 - loss: 0.0300 - val_accuracy: 1.0000 - val_loss: 6.0526e-06\n",
      "Epoch 76/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9914 - loss: 0.0262 - val_accuracy: 0.9994 - val_loss: 9.6944e-04\n",
      "Epoch 77/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9905 - loss: 0.0298 - val_accuracy: 1.0000 - val_loss: 5.1228e-06\n",
      "Epoch 78/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9912 - loss: 0.0280 - val_accuracy: 1.0000 - val_loss: 2.3113e-05\n",
      "Epoch 79/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9906 - loss: 0.0270 - val_accuracy: 1.0000 - val_loss: 6.3366e-05\n",
      "Epoch 80/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9888 - loss: 0.0337 - val_accuracy: 1.0000 - val_loss: 1.3958e-05\n",
      "Epoch 81/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9906 - loss: 0.0324 - val_accuracy: 0.9988 - val_loss: 0.0018\n",
      "Epoch 82/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9907 - loss: 0.0265 - val_accuracy: 0.9998 - val_loss: 3.3280e-04\n",
      "Epoch 83/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9893 - loss: 0.0333 - val_accuracy: 0.9998 - val_loss: 2.8919e-04\n",
      "Epoch 84/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9921 - loss: 0.0258 - val_accuracy: 0.9998 - val_loss: 2.2840e-04\n",
      "Epoch 85/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9884 - loss: 0.0354 - val_accuracy: 1.0000 - val_loss: 7.6938e-06\n",
      "Epoch 86/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9926 - loss: 0.0243 - val_accuracy: 1.0000 - val_loss: 1.0424e-04\n",
      "Epoch 87/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9893 - loss: 0.0309 - val_accuracy: 1.0000 - val_loss: 1.6639e-05\n",
      "Epoch 88/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9918 - loss: 0.0261 - val_accuracy: 1.0000 - val_loss: 2.8438e-04\n",
      "Epoch 89/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9896 - loss: 0.0307 - val_accuracy: 1.0000 - val_loss: 1.0618e-05\n",
      "Epoch 90/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9917 - loss: 0.0273 - val_accuracy: 1.0000 - val_loss: 1.7998e-06\n",
      "Epoch 91/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9920 - loss: 0.0216 - val_accuracy: 1.0000 - val_loss: 1.0709e-06\n",
      "Epoch 92/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9919 - loss: 0.0306 - val_accuracy: 1.0000 - val_loss: 3.1490e-06\n",
      "Epoch 93/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9921 - loss: 0.0243 - val_accuracy: 1.0000 - val_loss: 3.6247e-05\n",
      "Epoch 94/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9916 - loss: 0.0264 - val_accuracy: 1.0000 - val_loss: 3.4180e-06\n",
      "Epoch 95/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9917 - loss: 0.0240 - val_accuracy: 1.0000 - val_loss: 3.1510e-05\n",
      "Epoch 96/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9920 - loss: 0.0253 - val_accuracy: 1.0000 - val_loss: 2.7202e-05\n",
      "Epoch 97/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9912 - loss: 0.0294 - val_accuracy: 1.0000 - val_loss: 1.5510e-05\n",
      "Epoch 98/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9906 - loss: 0.0278 - val_accuracy: 1.0000 - val_loss: 2.2378e-07\n",
      "Epoch 99/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9923 - loss: 0.0238 - val_accuracy: 1.0000 - val_loss: 1.1876e-05\n",
      "Epoch 100/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9907 - loss: 0.0292 - val_accuracy: 0.9998 - val_loss: 4.6364e-04\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96      2608\n",
      "           1       0.98      0.97      0.98       246\n",
      "           2       0.95      0.98      0.96       279\n",
      "           3       0.83      0.69      0.75       252\n",
      "           4       0.88      0.97      0.92       246\n",
      "           5       0.95      0.95      0.95       258\n",
      "\n",
      "    accuracy                           0.95      3889\n",
      "   macro avg       0.93      0.92      0.92      3889\n",
      "weighted avg       0.95      0.95      0.95      3889\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_params = study.best_trial.params\n",
    "print(\"Лучшие параметры:\", best_params)\n",
    "\n",
    "smote = SMOTE(k_neighbors=best_params['k_neighbors'], sampling_strategy=best_params['sampling_strategy'])\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "def build_final_model(X_train, y_train):\n",
    "    model = Sequential([\n",
    "        Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(best_params['dropout_rate']),\n",
    "        Dense(128, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(best_params['dropout_rate']),\n",
    "        Dense(len(np.unique(y_train)), activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=best_params['learning_rate']),\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    model.fit(X_train, y_train, epochs=100, batch_size=best_params['batch_size'], validation_split=0.2, verbose=1)\n",
    "    return model\n",
    "\n",
    "final_model = build_final_model(X_train_smote, y_train_smote)\n",
    "\n",
    "# Предсказания\n",
    "y_pred = final_model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Отчёт о классификации\n",
    "report = classification_report(y_test, y_pred_classes)\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
